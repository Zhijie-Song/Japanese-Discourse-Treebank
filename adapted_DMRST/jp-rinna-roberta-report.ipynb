{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee17ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"\\depth_mode\\Savings\\jp-rinna-japanese-roberta-base_bs1_seed111\\\\\"\n",
    "data_path = r\"\\data\\pickle-data\\depth\\to_pt\\jp-rinna-japanese-roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ffa6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "import Metric\n",
    "from Metric import getBatchMeasure, getMicroMeasure, getMacroMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca47d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from Training import Train, EvalOnly, getAccuracy\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel, MBart50Tokenizer\n",
    "import config\n",
    "from model_depth import ParsingNet\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config.global_gpu_id)\n",
    "base_path = config.tree_infer_mode + \"_mode/\"\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available() #False\n",
    "device = torch.device(\"cuda:\" + str(config.global_gpu_id) if USE_CUDA else \"cpu\") #device(type='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0a256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "hidden_size = config.hidden_size\n",
    "rnn_layers = 1\n",
    "dropout_e = 0.5\n",
    "dropout_d = 0.5\n",
    "dropout_c = 0.5\n",
    "input_is_word = 'True'\n",
    "atten_model = 'Dotproduct'\n",
    "classifier_input_size = config.hidden_size #768\n",
    "classifier_hidden_size = int(config.hidden_size / 1) #768\n",
    "classifier_bias = 'True'\n",
    "use_org_Parseval = 'True'\n",
    "eval_only = 'True'\n",
    "\n",
    "seednumber = 111\n",
    "data_path_split = [x for x in data_path.split(os.sep) if x != \"\"]\n",
    "data_base = data_path_split[-1] #'zh-gcdt-hfl-chinese-roberta-wwm-ext'\n",
    "savepath = r\"Savings\\jp-rinna-japanese-roberta-base_bs1_seed111\\\\\"\n",
    "finetuning = \"False\"\n",
    "if savepath == None and finetuning == \"True\":\n",
    "    assert False\n",
    "elif savepath == None and finetuning == \"False\":\n",
    "    save_path = base_path + \"Savings/%s_bs%d_seed%d/\" % (data_base, batch_size, seednumber)\n",
    "    finetune_frompath = None\n",
    "elif savepath != None and finetuning == \"True\":\n",
    "    finetune_frompath = base_path + savepath\n",
    "    save_path = finetune_frompath.replace(\"Savings/\", \"Savings/finetuned_\")\n",
    "elif savepath != None and finetuning == \"False\":\n",
    "    finetune_frompath = None\n",
    "    save_path = base_path + savepath\n",
    "        \n",
    "eval_size = 1\n",
    "epoch = 50\n",
    "lr = 0.0002\n",
    "lr_decay_epoch = 1\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27514c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language embedding name:  rinna/japanese-roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at rinna/japanese-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language embedding loaded from pretrained:  rinna/japanese-roberta-base\n"
     ]
    }
   ],
   "source": [
    "# get language embedding\n",
    "language_embedding_name = re.sub(r\"jp-\", \"\", re.sub(r\".*gcdt-\", \"\", (re.sub(r\".*rstdt-\", \"\", re.sub(r\".*gum-\", \"\", data_base)))))\n",
    "language_embedding_name = language_embedding_name.replace(\"rinna-\", \"rinna/\")\n",
    "language_embedding_name = language_embedding_name.replace(\"hfl-\", \"hfl/\").replace(\"SpanBERT-\", \"SpanBERT/\")\n",
    "# 'hfl/chinese-roberta-wwm-ext' a model on Hugging Face\n",
    "\n",
    "\"\"\" BERT tokenizer and model \"\"\"\n",
    "print(\"language embedding name: \", language_embedding_name)\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(language_embedding_name, use_fast=True)\n",
    "bert_model = AutoModel.from_pretrained(language_embedding_name)\n",
    "print(\"Language embedding loaded from pretrained: \", language_embedding_name)\n",
    "\n",
    "\"\"\" freeze some layers \"\"\"\n",
    "for name, param in bert_model.named_parameters():\n",
    "    layer_num = re.findall(\"layer\\.(\\d+)\\.\", name)\n",
    "    if len(layer_num) > 0 and int(layer_num[0]) > 2:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "if USE_CUDA:\n",
    "    language_model = bert_model.cuda()\n",
    "else:\n",
    "    language_model = bert_model\n",
    "\n",
    "# Setting random seeds \n",
    "torch.manual_seed(seednumber)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed_all(seednumber)\n",
    "np.random.seed(seednumber)\n",
    "random.seed(seednumber)\n",
    "\n",
    "# Process bool args       \n",
    "if classifier_bias == 'True':\n",
    "    classifier_bias = True\n",
    "    # True\n",
    "\n",
    "elif classifier_bias == 'False':\n",
    "    classifier_bias = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70233c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr_InputSentences = []\n",
    "Tr_EDUBreaks = []\n",
    "Tr_DecoderInput = []\n",
    "Tr_RelationLabel = []\n",
    "Tr_ParsingBreaks = []\n",
    "Tr_GoldenMetric = []\n",
    "Tr_ParentsIndex = []\n",
    "Tr_SiblingIndex = []\n",
    "\n",
    "Dev_InputSentences = []\n",
    "Dev_EDUBreaks = []\n",
    "Dev_DecoderInput = []\n",
    "Dev_RelationLabel = []\n",
    "Dev_ParsingBreaks = []\n",
    "Dev_GoldenMetric = []\n",
    "Dev_ParentsIndex = []\n",
    "Dev_SiblingIndex = []\n",
    "\n",
    "# Load Testing data\n",
    "Test_InputSentences = []\n",
    "Test_EDUBreaks = []\n",
    "Test_DecoderInput = []\n",
    "Test_RelationLabel = []\n",
    "Test_ParsingBreaks = []\n",
    "Test_GoldenMetric = []\n",
    "\n",
    "# Load Training data\n",
    "Tr_InputSentences.extend(pickle.load(open(os.path.join(data_path, \"Training_InputSentences.pickle\"), \"rb\")))\n",
    "Tr_EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"Training_EDUBreaks.pickle\"), \"rb\")))\n",
    "Tr_DecoderInput.extend(pickle.load(open(os.path.join(data_path, \"Training_DecoderInputs.pickle\"), \"rb\")))\n",
    "Tr_RelationLabel.extend(pickle.load(open(os.path.join(data_path, \"Training_RelationLabel.pickle\"), \"rb\")))\n",
    "Tr_ParsingBreaks.extend(pickle.load(open(os.path.join(data_path, \"Training_ParsingIndex.pickle\"), \"rb\")))\n",
    "Tr_GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"Training_GoldenLabelforMetric.pickle\"), \"rb\")))\n",
    "Tr_ParentsIndex.extend(pickle.load(open(os.path.join(data_path, \"Training_ParentsIndex.pickle\"), \"rb\")))\n",
    "Tr_SiblingIndex.extend(pickle.load(open(os.path.join(data_path, \"Training_Sibling.pickle\"), \"rb\")))\n",
    "\n",
    "# Load Deving data\n",
    "Dev_InputSentences.extend(pickle.load(open(os.path.join(data_path, \"Deving_InputSentences.pickle\"), \"rb\")))\n",
    "Dev_EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"Deving_EDUBreaks.pickle\"), \"rb\")))\n",
    "Dev_DecoderInput.extend(pickle.load(open(os.path.join(data_path, \"Deving_DecoderInputs.pickle\"), \"rb\")))\n",
    "Dev_RelationLabel.extend(pickle.load(open(os.path.join(data_path, \"Deving_RelationLabel.pickle\"), \"rb\")))\n",
    "Dev_ParsingBreaks.extend(pickle.load(open(os.path.join(data_path, \"Deving_ParsingIndex.pickle\"), \"rb\")))\n",
    "Dev_GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"Deving_GoldenLabelforMetric.pickle\"), \"rb\")))\n",
    "Dev_ParentsIndex.extend(pickle.load(open(os.path.join(data_path, \"Deving_ParentsIndex.pickle\"), \"rb\")))\n",
    "Dev_SiblingIndex.extend(pickle.load(open(os.path.join(data_path, \"Deving_Sibling.pickle\"), \"rb\")))\n",
    "\n",
    "# Load Testing data\n",
    "Test_InputSentences.extend(pickle.load(open(os.path.join(data_path, \"Testing_InputSentences.pickle\"), \"rb\")))\n",
    "Test_EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"Testing_EDUBreaks.pickle\"), \"rb\")))\n",
    "Test_DecoderInput.extend(pickle.load(open(os.path.join(data_path, \"Testing_DecoderInputs.pickle\"), \"rb\")))\n",
    "Test_RelationLabel.extend(pickle.load(open(os.path.join(data_path, \"Testing_RelationLabel.pickle\"), \"rb\")))\n",
    "Test_ParsingBreaks.extend(pickle.load(open(os.path.join(data_path, \"Testing_ParsingIndex.pickle\"), \"rb\")))\n",
    "Test_GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"Testing_GoldenLabelforMetric.pickle\"), \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28e4503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Data...\n",
      " ▁ 加藤 ▁ 周 一 ▁ の ▁「 ▁ 眼 ▁ 」 ▁ と ▁「 ▁ 耳 ▁ 」 ▁ 加 國 ▁尚 志 ▁ メル ロ ▁= ▁ ポン ティ ▁ 晩年 ▁ の ▁ 哲学 ▁ 概念 ▁ に ▁「 ▁ 肉 ▁la ▁cha ir ▁ 」 ▁ と ▁ いう ▁ 概念 ▁ が ▁ある ▁ 。 ▁これ ▁ は ▁たとえば ▁ 右手 ▁ と ▁ 左手 ▁ を ▁ 重ね 合わせる ▁ とき ▁ 、 ▁ 触れ る ▁ 手 ▁ と ▁ 触れ ▁ られる ▁ 手 ▁ の ▁ 間 ▁ に ▁ 可逆 ▁ 的 ▁ で ▁ あい まい ▁ な ▁ 感覚 ▁ が ▁ 生じ ▁ 、 ▁ 主 観 ▁ と ▁ 客 観 ▁ 、 ▁ 能 動 ▁ と ▁ 受 動 ▁ が ▁ 相互 ▁ に ▁ 移り ▁ 行き あう ▁ よう ▁ な ▁「 ▁ 感じ ▁ られる ▁ もの ▁le ▁se ns ible ▁ 」 ▁ を ▁ 言い 表 し ▁ た ▁ もの ▁ で ▁ある ▁ 。 ▁この ▁「 ▁ 感じ ▁ られる ▁ もの ▁ 」 ▁ は ▁「 ▁ 見える ▁ もの ▁ 」 ▁ や ▁「 ▁ 触れ ▁ うる ▁ もの ▁ 」 ▁ に ▁ 宿 り ▁ 、 ▁さらに ▁ は ▁それ ▁ ら ▁ 相互 ▁ の ▁ 転移 ▁ を ▁ 可能 ▁ に ▁ する ▁ 。 ▁この ▁「 ▁ 肉 ▁ 」 ▁ の ▁ 経験 ▁ が ▁たとえば ▁ 色 ▁ など ▁ の ▁ 質 ▁ の ▁ 経験 ▁ の ▁ 基礎 ▁ に ▁ あり ▁ 、 ▁ 感 性 ▁ 的 ▁ な ▁ 現象 ▁ を ▁ 現象 ▁ と ▁ し ▁ て ▁ 成立 ▁ さ ▁ せる ▁ 存在 論 ▁ 的 ▁ な ▁ 概念 ▁ と ▁ し ▁ て ▁ 主 客 ▁二 ▁元 ▁ 論 ▁ の ▁ 近代 ▁ 哲学 的 ▁ 図 式 ▁ を ▁ 解体 ▁ さ ▁ せる ▁ もの ▁ と ▁ なる ▁ こと ▁ を ▁ メル ロ ▁= ▁ ポン ティ ▁ は ▁ 目 論 ん ▁ で ▁ い ▁ た ▁ 。 ▁『 ▁ 眼 ▁ と ▁ 精神 ▁ 』 ▁( ▁1961 ▁ 年 ▁ ) ▁ は ▁この ▁「 ▁ 肉 ▁ 」 ▁ の ▁ 概念 ▁ を ▁ 絵画 ▁ や ▁ 彫刻 ▁ など ▁ の ▁ 美術 ▁ 作品 ▁ に ▁ 適用 ▁ しよう ▁ と ▁ し ▁ た ▁ 試み ▁ で ▁ある ▁ 。 ▁ 実 ▁ は ▁この ▁「 ▁ 肉 ▁ 」 ▁ と ▁ いう ▁ 概念 ▁ は ▁ 、 ▁ メル ロ ▁= ▁ ポン ティ ▁ に ▁ 先 立 っ ▁ て ▁ 、 ▁ すでに ▁ サル トル ▁ が ▁『 ▁ 存在 ▁ と ▁ 無 ▁ 』 ▁( ▁1943 ▁ 年 ▁ ) ▁ の ▁ 中 ▁ で ▁ 語 っ ▁ て ▁ い ▁ た ▁ もの ▁ で ▁ある ▁ 。 ▁ メル ロ ▁= ▁ ポン ティ ▁ が ▁その ▁ こと ▁ を ▁ 知 ら ▁ なか っ ▁ た ▁ はず ▁ は ▁ ない ▁ から ▁ 、 ▁ 彼 ▁ は ▁ サル トル ▁ の ▁ 哲学 ▁ を ▁ ほぼ ▁ 全面 的 ▁ に ▁ 批判 ▁ し ▁ ながら ▁ 、 ▁この ▁ 概念 ▁ の ▁ 有効性 ▁ を ▁ 認め ▁ 、 ▁ 独自 ▁ の ▁ 存在 論 ▁ 的 ▁ 文脈 ▁ で ▁ 展開 ▁ し ▁ た ▁ の ▁ だろう ▁ 。 ▁ サル トル ▁ の ▁ 場合 ▁ 、 ▁この ▁ 概念 ▁ は ▁ 男女 ▁( ▁ 異性 ▁ ) ▁ 間 ▁ の ▁「 ▁ 愛 撫 ▁ 」 ▁ に ▁ おい ▁ て ▁ 、 ▁ 両者 ▁ の ▁ 身体 ▁ が ▁ 快 感 ▁ に ▁ おい ▁ て ▁ 溶け 合う ▁ よう ▁ に ▁ 結び つく ▁ 状態 ▁ を ▁ 指 し ▁ て ▁ いる ▁ 。 ▁それ ▁ は ▁ 即 自 ▁( ▁ 物 ▁ ) ▁ と ▁ 対 自 ▁( ▁ 意識 ▁ ) ▁ 、 ▁ 対 自 ▁( ▁ 自己 ▁ と ▁ の ▁ 関係 ▁ ) ▁ と ▁ 対 他 ▁( ▁ 他者 ▁ と ▁ の ▁ 関係 ▁ ) ▁ と ▁ いう ▁ サル トル ▁ の ▁二 ▁元 ▁ 論 ▁ 的 ▁ な ▁ 対立 ▁ 図 式 ▁ を ▁ 破 る ▁ もの ▁ と ▁ な っ ▁ て ▁ いる ▁ 。 ▁ 加藤 ▁ 周 一 ▁ が ▁この ▁ サル トル ▁ の ▁「 ▁ 肉 ▁ 」 ▁ の ▁ 概念 ▁ に ▁ つい ▁ て ▁ 語 っ ▁ て ▁ いる ▁ 箇所 ▁ が ▁ある ▁ 。 ▁それ ▁ は ▁「 ▁ 絵 ▁ の ▁ なか ▁ の ▁ 女 ▁ たち ▁ 」 ▁- LSB - ▁ 1 ▁- RSB - ▁ と ▁ いう ▁ 、 ▁ 絵画 ▁ に ▁ つい ▁ て ▁ の ▁ 随筆 ▁ に ▁ おい ▁ て ▁ で ▁ある ▁ 。 ▁この ▁「 ▁ 絵 ▁ の ▁ なか ▁ の ▁ 女 ▁ たち ▁ 」 ▁ は ▁ 、 ▁ いわば ▁ 加藤 ▁ の ▁ 私的 ▁ 好み ▁( ▁ 趣味 ▁ ) ▁ に ▁ よ る ▁女性 ▁ 肖像 ▁ 画 論 ▁ 、 ▁ 裸 婦 ▁ 画 論 ▁ で ▁ あり ▁ 、 ▁ある ▁ 意味 ▁ で ▁ は ▁ 加藤 ▁ の ▁ エロ ティ シズム ▁ 論 ▁ で ▁ある ▁ 。 ▁ 歴史的 ▁ 知名度 ▁ や ▁ 重要性 ▁ が ▁ 配慮 ▁ さ ▁ れ ▁ て ▁ いる ▁ と ▁ は ▁ いえ ▁ 、 ▁ そこ ▁ で ▁ 語 ら ▁ れる ▁ 絵画 ▁ は ▁ 基本的 ▁ に ▁ 加藤 ▁ が ▁ 好 む ▁ 作品 ▁ で ▁ あり ▁ 、 ▁ 彼 ▁ が ▁ 感 銘 ▁ を ▁ 受け ▁ た ▁ 作品 ▁ で ▁ある ▁ と ▁ 見 ▁ て ▁ よい ▁ 。 ▁それ ▁ は ▁お の ず と ▁ 加藤 ▁ の ▁ 裸 婦 ▁ 像 ▁ あるいは ▁女性 ▁ の ▁ 裸 体 ▁ へ ▁ の ▁ 趣味 ▁ 嗜好 ▁ を ▁ 示す ▁ もの ▁ で ▁ あり ▁ 、 ▁ つき つめ れ ▁ ば ▁ 一人 ▁ の ▁ 男性 ▁ と ▁ し ▁ て ▁ の ▁ 加藤 ▁ の ▁ 性的 ▁ 嗜好 ▁( ▁ 志向 ▁ ) ▁ を ▁ かい ま 見 ▁ せる ▁ もの ▁ と ▁ な っ ▁ て ▁ いる ▁ 。 ▁たとえば ▁ 作者 ▁ 不詳 ▁ の ▁ インド ▁ の ▁ 細 密 ▁ 画 ▁ に ▁ おい ▁ て ▁ 、 ▁ 男性 ▁ が ▁ 膝 ▁ に ▁ 抱え ▁ た ▁女性 ▁ を ▁ 背後 ▁ から ▁ 愛 撫 ▁ し ▁ て ▁ いる ▁ 場面 ▁ を ▁ 描 い ▁ た ▁ 作品 ▁( ▁「 ▁ 男 ▁ の ▁ 右手 ▁ は ▁ 、 ▁ 薄 衣 ▁ の ▁ 上 ▁ から ▁ 女 ▁ の ▁ 乳 ▁ を ▁ 愛 撫 ▁ する ▁ 。 ▁ 〔 ▁ 中略 ▁ 〕 ▁ 男 ▁ は ▁その ▁ 瞬間 ▁ に ▁ 動く ▁ 指 先 ▁その ▁ もの ▁ で ▁ある ▁ 」 ▁( ▁3 12 ▁ ) ▁ ) ▁ 。 ▁ あるいは ▁ ゴー ギャン ▁ が ▁ 褐色 ▁ の ▁ 肌 ▁ を ▁ し ▁ た ▁ タ ヒ チ ▁ の ▁ 裸 婦 ▁ を ▁ 描 い ▁ た ▁『 ▁ か ぐ わし ▁ き ▁ 大地 ▁ 』 ▁( ▁「 ▁ 彼 ▁ が ▁その ▁ 美 ▁ を ▁ 発見 ▁ し ▁ ない ▁ ため ▁ に ▁ は ▁ 、 ▁ タ ヒ ティ ▁ の ▁ ゴー ギャン ▁ は ▁ 、 ▁ あまり ▁ に ▁ も ▁ 、 ▁その ▁ 肌 ▁ の ▁ 温 かさ ▁ 、 ▁ 微 か ▁ な ▁ 湿 り ▁ 、 ▁ 滑らか ▁ さ ▁ と ▁ いう ▁ べ から ▁ ざる ▁ 弾 力 ▁ を ▁ 、 ▁ 愛 し ▁ て ▁ い ▁ た ▁ の ▁ で ▁ あ ろう ▁ 」 ▁( ▁3 22 ▁ ) ▁ ) ▁ 。 ▁ あるいは ▁ クリ ム ト ▁ の ▁『 ▁ ダナ エ ▁ 』 ▁( ▁「 ▁その ▁ 腿 ▁ の ▁ 間 ▁ に ▁ 降り そ そ ぎ ▁ 溢れ る ▁ 雨 ▁ を ▁ 受け ▁ て ▁ 、 ▁ 恍 惚 ▁ と ▁ し ▁ て ▁ 眼 ▁ を ▁ 閉じ ▁ 、 ▁ 半ば ▁ 口 ▁ を ▁ 開 い ▁ て ▁ 、 ▁ 片 手 ▁ で ▁一方 ▁ の ▁ 乳 ▁ を ▁ 押 える ▁ 」 ▁( ▁3 36 ▁ ) ▁ ) ▁ 。 ▁ おそらく ▁ こう ▁ し ▁ た ▁ 列挙 ▁ の ▁ 頂点 ▁ に ▁ 来る ▁ の ▁ は ▁ 、 ▁ クラ ナッ ハ ▁ の ▁『 ▁ ヴェ ヌス ▁ 』 ▁ で ▁ あ ろう ▁( ▁「 ▁ 丸 い ▁ 小さな ▁ 乳 ▁ が ▁ 、 ▁ 胸 ▁ の ▁ 上 ▁ の ▁ 方 ▁ に ▁ な らん ▁ で ▁ い ▁ て ▁ 、 ▁ 細 腰 ▁ から ▁ 下 腹 ▁ に ▁ かけ ▁ て ▁ の ▁ 部分 ▁ が ▁ 長く ▁ 、 ▁両 ▁ 肢 ▁ は ▁ 殊 に ▁ 細長く ▁ て ▁ 、 ▁真 直 ぐ ▁ に ▁ 伸び ▁ て ▁ いる ▁ 。 ▁ 細い ▁ 身体 ▁ の ▁ 全体 ▁ の ▁ なか ▁ で ▁ 、 ▁ 膨 み ▁ の ▁ 目立つ ▁ ところ ▁ は ▁ 、 ▁ 腹部 ▁ と ▁ 太 腿 ▁ で ▁ある ▁ 」 ▁( ▁3 47 ▁ ) ▁ ) ▁ 。 ▁この ▁ よう ▁ に ▁ 見 ▁ て ▁ くる ▁ と ▁ 、 ▁ 加藤 ▁ が ▁ 読者 ▁ に ▁その ▁ 作品 ▁ の ▁ 特徴 ▁ を ▁ 示 そう ▁ と ▁ し ▁ て ▁ 、 ▁また ▁ 読者 ▁ の ▁ ま な ざ し ▁ を ▁ 作品 ▁ の ▁その ▁ 箇所 ▁ に ▁ 導 こう ▁ と ▁ し ▁ て ▁ 描く ▁ 描写 ▁ に ▁ は ▁ 、 ▁ は から ▁ ず ▁ も ▁ 加藤 ▁ の ▁ 視 線 ▁ と ▁それ ▁ を ▁ 支え る ▁ 欲 情 ▁ を ▁ 示 し ▁ て ▁ いる ▁ よう ▁ に ▁ 思 わ ▁ れる ▁ 。 ▁つまり ▁「 ▁ 乳 ▁ 」 ▁「 ▁ 弾 力 ▁ 」 ▁「 ▁ 腿 ▁ 」 ▁「 ▁ 下 腹 ▁ 」 ▁ ... ▁ 。 ▁それ ▁ は ▁ ヴェ ヌス ▁ の ▁ 細い ▁ 首 ▁ や ▁ 、 ▁ 衣 ▁ に ▁ 触れ る ▁ 指 先 ▁ に ▁ は ▁ 向 かわ ▁ ない ▁ 。 ▁それ ▁ ら ▁ は ▁ 曲線 ▁ を ▁ 示す ▁「 ▁ 下 腹 ▁ 」 ▁ と ▁ いう ▁ 図 ▁ を ▁ 際 立 た ▁ せる ▁ 地 ▁ の ▁ よう ▁ に ▁ 扱 わ ▁ れ ▁ て ▁ いる ▁ 。 ▁ したが っ ▁ て ▁ 、 ▁ 肩 ▁ や ▁ 背中 ▁ から ▁ 腰 ▁ に ▁ かけ ▁ て ▁ の ▁ 線 ▁ で ▁ は ▁ なく ▁ て ▁ 、 ▁ 丸 み ▁ を ▁ 帯 び ▁ た ▁「 ▁ 乳 ▁ 」 ▁ 、 ▁また ▁ 、 ▁女性 器 ▁ で ▁ は ▁ なく ▁ 太 腿 ▁ 、 ▁ 下 腹 ▁ 。 ▁ そこ ▁ に ▁ は ▁ 丸 み ▁ を ▁ 帯 び ▁ た ▁ 曲線 ▁ へ ▁ の ▁ 趣味 ▁ が ▁ 現れ ▁ て ▁ いる ▁( ▁ クール ベ ▁ の ▁『 ▁世界 ▁ の ▁ 起源 ▁ 』 ▁ は ▁ 、 ▁この ▁ 随筆 ▁ に ▁ は ▁ 登場 ▁ し ▁ ない ▁ ) ▁ 。 ▁もっとも ▁ 、 ▁ 加藤 ▁ 自身 ▁ は ▁ 十分 ▁ に ▁ 意識 的 ▁ に ▁この ▁ よう ▁ な ▁ 記述 ▁ を ▁ 行 な っ ▁ て ▁ いる ▁ 。 ▁ 次 ▁ の ▁一 ▁ 文 ▁ は ▁ 、 ▁ 加藤 ▁ が ▁ 視覚 ▁ の ▁ 内 ▁ で ▁ 感じる ▁ ことが ら ▁ 、 ▁つまり ▁「 ▁ 見える ▁ もの ▁ 」 ▁ の ▁ 中 ▁ に ▁「 ▁ 触れ ▁ うる ▁ もの ▁ 」 ▁ を ▁ 見る ▁ 感覚 ▁ を ▁ 示 し ▁ て ▁ いる ▁ 。\n",
      "... ...\n",
      "That's great! No error found!\n",
      "All train sample number: 24\n"
     ]
    }
   ],
   "source": [
    "# To check data\n",
    "sent_temp = ''\n",
    "print(\"Checking Data...\")\n",
    "for word_temp in Tr_InputSentences[2]:\n",
    "    sent_temp = sent_temp + ' ' + word_temp\n",
    "print(sent_temp)\n",
    "print('... ...')\n",
    "print(\"That's great! No error found!\")\n",
    "print(\"All train sample number:\", len(Tr_InputSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555fb3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save path depth_mode/Savings\\jp-rinna-japanese-roberta-base_bs1_seed111\\\\\n",
      "Finetune from path None\n"
     ]
    }
   ],
   "source": [
    "# To save model and data\n",
    "FileName = str(seednumber) + \"_\" + config.tree_infer_mode + '_Batch_' + str(batch_size) + 'Hidden_' + str(hidden_size) + \\\n",
    "            'LR' + str(lr) + \"_\" + str(time.time())\n",
    "\n",
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)\n",
    "print(\"Model save path\", save_path)\n",
    "print(\"Finetune from path\", finetune_frompath)\n",
    "        \n",
    "\n",
    "\"\"\" relation number is set at 42 \"\"\"\n",
    "if \"en-rstdt\" in data_path:\n",
    "    number_of_relations = 42\n",
    "elif \"-gum\" in data_path or \"-gcdt\" in data_path or \"jp\" in data_path:\n",
    "    number_of_relations = 30\n",
    "model = ParsingNet(language_model, hidden_size, hidden_size,\n",
    "                    hidden_size, atten_model, classifier_input_size, classifier_hidden_size, number_of_relations,\n",
    "                    classifier_bias, rnn_layers, dropout_e, dropout_d, dropout_c, bert_tokenizer=bert_tokenizer)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a15d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch EvalOnly Test:\t27\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.6804\t0.5069\t0.4573\n",
      "Epoch EvalOnly Test:\t27\tdocid:\t0\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7158\t0.4947\t0.4632\n",
      "Epoch EvalOnly Test:\t27\tdocid:\t1\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.6750\t0.5000\t0.4500\n",
      "Epoch EvalOnly Test:\t27\tdocid:\t2\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.6574\t0.5278\t0.4630\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # reduce memory\n",
    "        # Load model\n",
    "        torchsave_files = sorted(glob.glob(save_path + \"Epoch_*.torchsave\"))\n",
    "        assert len(torchsave_files) == 1\n",
    "        torchsave_best = torchsave_files[0]\n",
    "        best_epoch_Dev = int(re.search(r\"\\d+\", os.path.basename(torchsave_best)).group())\n",
    "            \n",
    "        model.load_state_dict(torch.load(torchsave_best, map_location=device))\n",
    "\n",
    "        # Convert model to eval\n",
    "        model.eval()\n",
    "\n",
    "        # Eval on Testing data\n",
    "        LossTree_Test, LossLabel_Test, span_points_Test, relation_points_Test, \\\n",
    "        nuclearity_points_Test, F1_full_Test, segment_points_Test = getAccuracy(Test_InputSentences,\n",
    "                                                                                Test_EDUBreaks,\n",
    "                                                                                Test_DecoderInput,\n",
    "                                                                                Test_RelationLabel,\n",
    "                                                                                Test_ParsingBreaks,\n",
    "                                                                                Test_GoldenMetric,\n",
    "                                                                                use_pred_segmentation=False,\n",
    "                                                                                use_org_Parseval=use_org_Parseval,\n",
    "                                                                                batch_size=eval_size,\n",
    "                                                                                model=model)\n",
    "        \n",
    "        # Unfold numbers\n",
    "        # Test\n",
    "        P_span_Test, R_span_Test, F_span_Test = span_points_Test\n",
    "        P_relation_Test, R_relation_Test, F_relation_Test = relation_points_Test\n",
    "        P_nuclearity_Test, R_nuclearity_Test, F_nuclearity_Test = nuclearity_points_Test\n",
    "        P_segment_Test, R_segment_Test, F_segment_Test = segment_points_Test\n",
    "        \n",
    "        print('Epoch EvalOnly Test:\\t%d\\n' % best_epoch_Dev,\n",
    "              'F_segment_Test\\tF_span_Test\\tF_nuclearity_Test\\tF_relation_Test:\\n%.4f\\t%.4f\\t%.4f\\t%.4f'\n",
    "              % (F_segment_Test, F_span_Test, F_nuclearity_Test, F_relation_Test))\n",
    "        \n",
    "        # Eval on each document\n",
    "        for docid in range(len(Test_InputSentences)):\n",
    "            LossTree_Test, LossLabel_Test, span_points_Test, relation_points_Test, \\\n",
    "            nuclearity_points_Test, F1_full_Test, segment_points_Test = getAccuracy([Test_InputSentences[docid]],\n",
    "                                                                                    [Test_EDUBreaks[docid]],\n",
    "                                                                                    [Test_DecoderInput[docid]],\n",
    "                                                                                    [Test_RelationLabel[docid]],\n",
    "                                                                                    [Test_ParsingBreaks[docid]],\n",
    "                                                                                    [Test_GoldenMetric[docid]],\n",
    "                                                                                    use_pred_segmentation=False,\n",
    "                                                                                    use_org_Parseval=use_org_Parseval,\n",
    "                                                                                    batch_size=eval_size,\n",
    "                                                                                    model=model)\n",
    "            \n",
    "            # Unfold numbers\n",
    "            # Test\n",
    "            P_span_Test, R_span_Test, F_span_Test = span_points_Test\n",
    "            P_relation_Test, R_relation_Test, F_relation_Test = relation_points_Test\n",
    "            P_nuclearity_Test, R_nuclearity_Test, F_nuclearity_Test = nuclearity_points_Test\n",
    "            P_segment_Test, R_segment_Test, F_segment_Test = segment_points_Test\n",
    "            \n",
    "            print('Epoch EvalOnly Test:\\t%d\\tdocid:\\t%d\\n' % (best_epoch_Dev, docid),\n",
    "                  'F_segment_Test\\tF_span_Test\\tF_nuclearity_Test\\tF_relation_Test:\\n%.4f\\t%.4f\\t%.4f\\t%.4f'\n",
    "                  % (F_segment_Test, F_span_Test, F_nuclearity_Test, F_relation_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5606bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoopNeeded = int(np.ceil(len(Test_EDUBreaks) / batch_size))\n",
    "\n",
    "Loss_tree_all = []\n",
    "Loss_label_all = []\n",
    "correct_span = 0\n",
    "correct_relation = 0\n",
    "correct_nuclearity = 0\n",
    "correct_full = 0\n",
    "no_system = 0\n",
    "no_golden = 0\n",
    "no_gold_seg = 0\n",
    "no_pred_seg = 0\n",
    "no_correct_seg = 0\n",
    "\n",
    "correct_span_list = []\n",
    "correct_relation_list = []\n",
    "correct_nuclearity_list = []\n",
    "no_system_list = []\n",
    "no_golden_list = []\n",
    "\n",
    "all_label_gold = []\n",
    "all_label_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6090593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training import getBatchData\n",
    "\n",
    "with torch.no_grad():\n",
    "    for loop in range(LoopNeeded):\n",
    "\n",
    "        StartPosition = loop * batch_size\n",
    "        EndPosition = (loop + 1) * batch_size\n",
    "        if EndPosition > len(Test_EDUBreaks):\n",
    "            EndPosition = len(Test_EDUBreaks)\n",
    "\n",
    "        InputSentences_batch, EDUBreaks_batch, _, RelationLabel_batch, ParsingBreaks_batch, GoldenMetric_batch = \\\n",
    "            getBatchData(Test_InputSentences[StartPosition:EndPosition],\n",
    "                         Test_EDUBreaks[StartPosition:EndPosition],\n",
    "                         Test_DecoderInput[StartPosition:EndPosition],\n",
    "                         Test_RelationLabel[StartPosition:EndPosition],\n",
    "                         Test_ParsingBreaks[StartPosition:EndPosition],\n",
    "                         Test_GoldenMetric[StartPosition:EndPosition], batch_size)\n",
    "\n",
    "        Loss_tree_batch, Loss_label_batch, SPAN_batch, Label_Tuple_batch, predict_EDU_breaks = model.TestingLoss(\n",
    "            InputSentences_batch, EDUBreaks_batch, RelationLabel_batch,\n",
    "            ParsingBreaks_batch, GenerateTree=True, use_pred_segmentation=False)\n",
    "\n",
    "        all_label_gold.extend(Label_Tuple_batch[0])\n",
    "        all_label_pred.extend(Label_Tuple_batch[1])\n",
    "\n",
    "        Loss_tree_all.append(Loss_tree_batch)\n",
    "        Loss_label_all.append(Loss_label_batch)\n",
    "\n",
    "        correct_span_batch, correct_relation_batch, correct_nuclearity_batch, correct_full_batch, no_system_batch, no_golden_batch, \\\n",
    "        correct_span_batch_list, correct_relation_batch_list, correct_nuclearity_batch_list, \\\n",
    "        no_system_batch_list, no_golden_batch_list, segment_results_list = getBatchMeasure(SPAN_batch,\n",
    "                                                                                           GoldenMetric_batch,\n",
    "                                                                                           predict_EDU_breaks,\n",
    "                                                                                           EDUBreaks_batch,\n",
    "                                                                                           use_org_Parseval)\n",
    "\n",
    "        correct_span = correct_span + correct_span_batch\n",
    "        correct_relation = correct_relation + correct_relation_batch\n",
    "        correct_nuclearity = correct_nuclearity + correct_nuclearity_batch\n",
    "        correct_full = correct_full + correct_full_batch\n",
    "        no_system = no_system + no_system_batch\n",
    "        no_golden = no_golden + no_golden_batch\n",
    "        no_gold_seg += segment_results_list[0]\n",
    "        no_pred_seg += segment_results_list[1]\n",
    "        no_correct_seg += segment_results_list[2]\n",
    "\n",
    "        correct_span_list += correct_span_batch_list\n",
    "        correct_relation_list += correct_relation_batch_list\n",
    "        correct_nuclearity_list += correct_nuclearity_batch_list\n",
    "        no_system_list += no_system_batch_list\n",
    "        no_golden_list += no_golden_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1133461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_points, relation_points, nuclearity_points, F1_Full, segment_points = getMicroMeasure(correct_span,\n",
    "                                                                                           correct_relation,\n",
    "                                                                                           correct_nuclearity,\n",
    "                                                                                           correct_full,\n",
    "                                                                                           no_system,\n",
    "                                                                                           no_golden,\n",
    "                                                                                           no_gold_seg,\n",
    "                                                                                           no_pred_seg,\n",
    "                                                                                           no_correct_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b7995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Loss_tree, Loss_label, SPAN, Label_Tuple, predict_EDU_breaks = model.TestingLoss(\n",
    "        Test_InputSentences, Test_EDUBreaks, Test_RelationLabel,\n",
    "        Test_ParsingBreaks, GenerateTree=True, use_pred_segmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdac3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_span_1, correct_relation_1, correct_nuclearity_1, correct_full_1, no_system_1, no_golden_1, \\\n",
    "        correct_span_list_1, correct_relation_list_1, correct_nuclearity_list_1, \\\n",
    "        no_system_list_1, no_golden_list_1, segment_results_list_1 = getBatchMeasure(SPAN,\n",
    "                                                                                     Test_GoldenMetric,\n",
    "                                                                                     predict_EDU_breaks,\n",
    "                                                                                     Test_EDUBreaks,\n",
    "                                                                                     use_org_Parseval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e11aa228",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dic_list = []\n",
    "for i in range(len(SPAN)):\n",
    "    predict_dic_list.append(Metric.getEvalData_parseval(SPAN[i][0], predict_EDU_breaks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b03131",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dic_list = []\n",
    "for i in range(len(Test_GoldenMetric)):\n",
    "    gold_dic_list.append(Metric.getEvalData_parseval(Test_GoldenMetric[i][0], Test_EDUBreaks[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c6df2",
   "metadata": {},
   "source": [
    "# Report on Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21cff4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predict_dic_list, gold_dic_list):\n",
    "    \n",
    "    span_correct = 0\n",
    "    nuc_correct = 0\n",
    "    rel_correct = 0\n",
    "    length = 0\n",
    "    \n",
    "    for i in range(len(gold_dic_list)):\n",
    "        length += len(gold_dic_list[i])\n",
    "        for key in gold_dic_list[i].keys():\n",
    "            if key in predict_dic_list[i].keys():\n",
    "                span_correct += 1\n",
    "                if gold_dic_list[i][key][0] == predict_dic_list[i][key][0]:\n",
    "                    rel_correct += 1\n",
    "                if gold_dic_list[i][key][1] == predict_dic_list[i][key][1]:\n",
    "                    nuc_correct += 1\n",
    "    \n",
    "    span = span_correct / length\n",
    "    nuc = nuc_correct / length\n",
    "    rel = rel_correct / length\n",
    "    \n",
    "    return span, nuc, rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5441d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6804407713498623\n",
      "0.5068870523415978\n",
      "0.4573002754820937\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list, gold_dic_list)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2473726",
   "metadata": {},
   "source": [
    "# Report on Rel Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e61ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_rel_type(predict_dic_list, gold_dic_list):\n",
    "    \n",
    "    relname_accuracy = {}\n",
    "    \n",
    "    for i in range(len(gold_dic_list)):\n",
    "        for key in gold_dic_list[i].keys():\n",
    "            rel = gold_dic_list[i][key][0]\n",
    "            nuc = gold_dic_list[i][key][1]\n",
    "            if rel not in relname_accuracy:\n",
    "                relname_accuracy[rel] = [0, 1]\n",
    "            else:\n",
    "                relname_accuracy[rel][1] += 1\n",
    "            if key in predict_dic_list[i].keys():\n",
    "                if rel == predict_dic_list[i][key][0] and nuc == predict_dic_list[i][key][1]:\n",
    "                    relname_accuracy[rel][0] +=1\n",
    "    \n",
    "    return relname_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5240abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "relname_accuracy = report_rel_type(predict_dic_list, gold_dic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7041c76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [4, 6],\n",
       " 'elaboration': [41, 76],\n",
       " 'attribution': [1, 6],\n",
       " 'joint': [54, 112],\n",
       " 'context': [4, 27],\n",
       " 'same-unit': [31, 45],\n",
       " 'adversative': [7, 14],\n",
       " 'contingency': [0, 7],\n",
       " 'purpose': [1, 4],\n",
       " 'explanation': [16, 30],\n",
       " 'restatement': [0, 1],\n",
       " 'mode': [4, 10],\n",
       " 'causal': [2, 20],\n",
       " 'evaluation': [0, 4],\n",
       " 'topic': [0, 1]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relname_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa004c",
   "metadata": {},
   "source": [
    "# Report on Intra- and Inter-sentential Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e02fc108",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_seg = []\n",
    "for i in range(len(Test_EDUBreaks)):\n",
    "    doc_sent_seg = []\n",
    "    for index in Test_EDUBreaks[i]:\n",
    "        if Test_InputSentences[i][index] in ['。', '？', '！', '.', '?', '!']:\n",
    "            doc_sent_seg.append(index)\n",
    "    sent_seg.append(doc_sent_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1930a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_intra(dic_list, sent_seg):\n",
    "    \n",
    "    filtered = []\n",
    "    \n",
    "    for i in range(len(dic_list)):\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        for key in dic_list[i].keys():\n",
    "            start, end = map(int, key.split('-'))\n",
    "            count_in_range = sum(start <= num < end for num in sent_seg[i])\n",
    "            if count_in_range == 0:\n",
    "                result.update({key: dic_list[i][key]})\n",
    "                \n",
    "        filtered.append(result)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4e1272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_gold = filter_intra(gold_dic_list, sent_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1e871ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_gold = []\n",
    "\n",
    "for i in range(len(gold_dic_list)):\n",
    "    inter_gold.append({key : value for key, value in gold_dic_list[i].items() if key not in intra_gold[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "970e62b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elaboration': [41, 53],\n",
       " 'same-unit': [31, 45],\n",
       " 'joint': [37, 53],\n",
       " 'contingency': [0, 7],\n",
       " 'purpose': [1, 4],\n",
       " 'adversative': [7, 11],\n",
       " 'mode': [4, 10],\n",
       " 'explanation': [16, 21],\n",
       " 'context': [1, 8],\n",
       " 'causal': [2, 12],\n",
       " 'attribution': [1, 4]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list, intra_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd3402a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [4, 6],\n",
       " 'attribution': [0, 2],\n",
       " 'joint': [17, 59],\n",
       " 'context': [3, 19],\n",
       " 'adversative': [0, 3],\n",
       " 'elaboration': [0, 23],\n",
       " 'explanation': [0, 9],\n",
       " 'restatement': [0, 1],\n",
       " 'causal': [0, 8],\n",
       " 'evaluation': [0, 4],\n",
       " 'topic': [0, 1]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list, inter_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98bfd927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8552631578947368\n",
      "0.6710526315789473\n",
      "0.6228070175438597\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list, intra_gold)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c191f76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3851851851851852\n",
      "0.22962962962962963\n",
      "0.17777777777777778\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list, inter_gold)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d3c1de",
   "metadata": {},
   "source": [
    "# Report on Intra-sentential Spans in the Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "064ecd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDUBreaks = []\n",
    "GoldenMetric = []\n",
    "InputSentences = []\n",
    "EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"EDUBreaks.pickle\"), \"rb\")))\n",
    "GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"GoldenLabelforMetric.pickle\"), \"rb\")))\n",
    "InputSentences.extend(pickle.load(open(os.path.join(data_path, \"InputSentences.pickle\"), \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e78e656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = []\n",
    "for i in range(len(EDUBreaks)):\n",
    "    doc_sent_seg = []\n",
    "    for index in EDUBreaks[i]:\n",
    "        if InputSentences[i][index] in ['。', '？', '！', '.', '?', '!']:\n",
    "            doc_sent_seg.append(index)\n",
    "    seg.append(doc_sent_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6902bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dic_list_all = []\n",
    "for i in range(len(GoldenMetric)):\n",
    "    gold_dic_list_all.append(Metric.getEvalData_parseval(GoldenMetric[i][0], EDUBreaks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7041e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_all = filter_intra(gold_dic_list_all, seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2d447c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6883755222413369\n"
     ]
    }
   ],
   "source": [
    "print(sum(len(doc) for doc in intra_all) / sum(len(doc) for doc in gold_dic_list_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
