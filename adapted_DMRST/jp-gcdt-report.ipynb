{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b346e6",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee17ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"\\depth_mode\\Savings\\jp-gcdt-xlm-roberta-base_bs1_seed111\\\\\"\n",
    "data_path = r\"\\data\\pickle-data\\depth\\to_pt\\jp-gcdt-xlm-roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ffa6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "import Metric\n",
    "from Metric import getBatchMeasure, getMicroMeasure, getMacroMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca47d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from Training import Train, EvalOnly, getAccuracy\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel, MBart50Tokenizer\n",
    "import config\n",
    "from model_depth import ParsingNet\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config.global_gpu_id)\n",
    "base_path = config.tree_infer_mode + \"_mode/\"\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available() #False\n",
    "device = torch.device(\"cuda:\" + str(config.global_gpu_id) if USE_CUDA else \"cpu\") #device(type='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0a256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "hidden_size = config.hidden_size\n",
    "rnn_layers = 1\n",
    "dropout_e = 0.5\n",
    "dropout_d = 0.5\n",
    "dropout_c = 0.5\n",
    "input_is_word = 'True'\n",
    "atten_model = 'Dotproduct'\n",
    "classifier_input_size = config.hidden_size #768\n",
    "classifier_hidden_size = int(config.hidden_size / 1) #768\n",
    "classifier_bias = 'True'\n",
    "use_org_Parseval = 'True'\n",
    "eval_only = 'True'\n",
    "\n",
    "seednumber = 111\n",
    "data_path_split = [x for x in data_path.split(os.sep) if x != \"\"]\n",
    "data_base = data_path_split[-1] #'zh-gcdt-hfl-chinese-roberta-wwm-ext'\n",
    "savepath = r\"Savings\\jp-gcdt-xlm-roberta-base_bs1_seed111\\\\\"\n",
    "finetuning = \"False\"\n",
    "if savepath == None and finetuning == \"True\":\n",
    "    assert False\n",
    "elif savepath == None and finetuning == \"False\":\n",
    "    save_path = base_path + \"Savings/%s_bs%d_seed%d/\" % (data_base, batch_size, seednumber)\n",
    "    finetune_frompath = None\n",
    "elif savepath != None and finetuning == \"True\":\n",
    "    finetune_frompath = base_path + savepath\n",
    "    save_path = finetune_frompath.replace(\"Savings/\", \"Savings/finetuned_\")\n",
    "elif savepath != None and finetuning == \"False\":\n",
    "    finetune_frompath = None\n",
    "    save_path = base_path + savepath\n",
    "        \n",
    "eval_size = 1\n",
    "epoch = 50\n",
    "lr = 0.0002\n",
    "lr_decay_epoch = 1\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27514c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language embedding name:  xlm-roberta-base\n",
      "Language embedding loaded from pretrained:  xlm-roberta-base\n"
     ]
    }
   ],
   "source": [
    "# get language embedding\n",
    "language_embedding_name = re.sub(r\".*jp-\", \"\", re.sub(r\".*gcdt-\", \"\", (re.sub(r\".*rstdt-\", \"\", re.sub(r\".*gum-\", \"\", data_base)))))\n",
    "language_embedding_name = language_embedding_name.replace(\"hfl-\", \"hfl/\").replace(\"SpanBERT-\", \"SpanBERT/\")\n",
    "# 'hfl/chinese-roberta-wwm-ext' a model on Hugging Face\n",
    "\n",
    "\"\"\" BERT tokenizer and model \"\"\"\n",
    "print(\"language embedding name: \", language_embedding_name)\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(language_embedding_name, use_fast=True)\n",
    "bert_model = AutoModel.from_pretrained(language_embedding_name)\n",
    "print(\"Language embedding loaded from pretrained: \", language_embedding_name)\n",
    "\n",
    "\"\"\" freeze some layers \"\"\"\n",
    "for name, param in bert_model.named_parameters():\n",
    "    layer_num = re.findall(\"layer\\.(\\d+)\\.\", name)\n",
    "    if len(layer_num) > 0 and int(layer_num[0]) > 2:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "if USE_CUDA:\n",
    "    language_model = bert_model.cuda()\n",
    "else:\n",
    "    language_model = bert_model\n",
    "\n",
    "# Setting random seeds \n",
    "torch.manual_seed(seednumber)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed_all(seednumber)\n",
    "np.random.seed(seednumber)\n",
    "random.seed(seednumber)\n",
    "\n",
    "# Process bool args       \n",
    "if classifier_bias == 'True':\n",
    "    classifier_bias = True\n",
    "    # True\n",
    "\n",
    "elif classifier_bias == 'False':\n",
    "    classifier_bias = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70233c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr_InputSentences = []\n",
    "Tr_EDUBreaks = []\n",
    "Tr_DecoderInput = []\n",
    "Tr_RelationLabel = []\n",
    "Tr_ParsingBreaks = []\n",
    "Tr_GoldenMetric = []\n",
    "Tr_ParentsIndex = []\n",
    "Tr_SiblingIndex = []\n",
    "\n",
    "Dev_InputSentences = []\n",
    "Dev_EDUBreaks = []\n",
    "Dev_DecoderInput = []\n",
    "Dev_RelationLabel = []\n",
    "Dev_ParsingBreaks = []\n",
    "Dev_GoldenMetric = []\n",
    "Dev_ParentsIndex = []\n",
    "Dev_SiblingIndex = []\n",
    "\n",
    "# Load Testing data\n",
    "Test_InputSentences = []\n",
    "Test_EDUBreaks = []\n",
    "Test_DecoderInput = []\n",
    "Test_RelationLabel = []\n",
    "Test_ParsingBreaks = []\n",
    "Test_GoldenMetric = []\n",
    "\n",
    "# Load Training data\n",
    "Tr_InputSentences.extend(pickle.load(open(os.path.join(data_path, \"Training_InputSentences.pickle\"), \"rb\")))\n",
    "Tr_EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"Training_EDUBreaks.pickle\"), \"rb\")))\n",
    "Tr_DecoderInput.extend(pickle.load(open(os.path.join(data_path, \"Training_DecoderInputs.pickle\"), \"rb\")))\n",
    "Tr_RelationLabel.extend(pickle.load(open(os.path.join(data_path, \"Training_RelationLabel.pickle\"), \"rb\")))\n",
    "Tr_ParsingBreaks.extend(pickle.load(open(os.path.join(data_path, \"Training_ParsingIndex.pickle\"), \"rb\")))\n",
    "Tr_GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"Training_GoldenLabelforMetric.pickle\"), \"rb\")))\n",
    "Tr_ParentsIndex.extend(pickle.load(open(os.path.join(data_path, \"Training_ParentsIndex.pickle\"), \"rb\")))\n",
    "Tr_SiblingIndex.extend(pickle.load(open(os.path.join(data_path, \"Training_Sibling.pickle\"), \"rb\")))\n",
    "\n",
    "# Load Deving data\n",
    "Dev_InputSentences.extend(pickle.load(open(os.path.join(data_path, \"Deving_InputSentences.pickle\"), \"rb\")))\n",
    "Dev_EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"Deving_EDUBreaks.pickle\"), \"rb\")))\n",
    "Dev_DecoderInput.extend(pickle.load(open(os.path.join(data_path, \"Deving_DecoderInputs.pickle\"), \"rb\")))\n",
    "Dev_RelationLabel.extend(pickle.load(open(os.path.join(data_path, \"Deving_RelationLabel.pickle\"), \"rb\")))\n",
    "Dev_ParsingBreaks.extend(pickle.load(open(os.path.join(data_path, \"Deving_ParsingIndex.pickle\"), \"rb\")))\n",
    "Dev_GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"Deving_GoldenLabelforMetric.pickle\"), \"rb\")))\n",
    "Dev_ParentsIndex.extend(pickle.load(open(os.path.join(data_path, \"Deving_ParentsIndex.pickle\"), \"rb\")))\n",
    "Dev_SiblingIndex.extend(pickle.load(open(os.path.join(data_path, \"Deving_Sibling.pickle\"), \"rb\")))\n",
    "\n",
    "# Load Testing data\n",
    "Test_InputSentences.extend(pickle.load(open(os.path.join(data_path, \"Testing_InputSentences.pickle\"), \"rb\")))\n",
    "Test_EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"Testing_EDUBreaks.pickle\"), \"rb\")))\n",
    "Test_DecoderInput.extend(pickle.load(open(os.path.join(data_path, \"Testing_DecoderInputs.pickle\"), \"rb\")))\n",
    "Test_RelationLabel.extend(pickle.load(open(os.path.join(data_path, \"Testing_RelationLabel.pickle\"), \"rb\")))\n",
    "Test_ParsingBreaks.extend(pickle.load(open(os.path.join(data_path, \"Testing_ParsingIndex.pickle\"), \"rb\")))\n",
    "Test_GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"Testing_GoldenLabelforMetric.pickle\"), \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28e4503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Data...\n",
      " ▁ 加 藤 ▁ 周一 ▁ の ▁「 ▁ 眼 ▁ 」 ▁ と ▁「 ▁ 耳 ▁ 」 ▁ 加 國 ▁ 尚 志 ▁ メ ル ロ ▁= ▁ ポン ティ ▁ 晩 年 ▁ の ▁ 哲学 ▁ 概念 ▁ に ▁「 ▁ 肉 ▁la ▁chair ▁ 」 ▁ と ▁ いう ▁ 概念 ▁ が ▁ ある ▁ 。 ▁ これ ▁ は ▁ たとえば ▁ 右手 ▁ と ▁ 左 手 ▁ を ▁ 重 ね 合わせ る ▁ とき ▁ 、 ▁ 触れ る ▁ 手 ▁ と ▁ 触れ ▁ られる ▁ 手 ▁ の ▁ 間 ▁ に ▁ 可 逆 ▁ 的 ▁ で ▁ あい まい ▁ な ▁ 感覚 ▁ が ▁ 生 じ ▁ 、 ▁ 主 観 ▁ と ▁ 客 観 ▁ 、 ▁ 能 動 ▁ と ▁ 受 動 ▁ が ▁ 相互 ▁ に ▁ 移 り ▁ 行き あ う ▁ よう ▁ な ▁「 ▁ 感じ ▁ られる ▁ もの ▁le ▁sensible ▁ 」 ▁ を ▁ 言い 表 し ▁ た ▁ もの ▁ で ▁ ある ▁ 。 ▁この ▁「 ▁ 感じ ▁ られる ▁ もの ▁ 」 ▁ は ▁「 ▁ 見える ▁ もの ▁ 」 ▁ や ▁「 ▁ 触れ ▁ う る ▁ もの ▁ 」 ▁ に ▁ 宿 り ▁ 、 ▁ さらに ▁ は ▁それ ▁ ら ▁ 相互 ▁ の ▁ 転 移 ▁ を ▁ 可能 ▁ に ▁ する ▁ 。 ▁この ▁「 ▁ 肉 ▁ 」 ▁ の ▁ 経験 ▁ が ▁ たとえば ▁ 色 ▁ など ▁ の ▁ 質 ▁ の ▁ 経験 ▁ の ▁ 基礎 ▁ に ▁ あり ▁ 、 ▁ 感 性 ▁ 的 ▁ な ▁ 現象 ▁ を ▁ 現象 ▁ と ▁ し ▁ て ▁ 成立 ▁ さ ▁ せる ▁ 存在 論 ▁ 的 ▁ な ▁ 概念 ▁ と ▁ し ▁ て ▁ 主 客 ▁二 ▁ 元 ▁ 論 ▁ の ▁ 近代 ▁ 哲学 的 ▁ 図 式 ▁ を ▁ 解 体 ▁ さ ▁ せる ▁ もの ▁ と ▁ なる ▁ こと ▁ を ▁ メ ル ロ ▁= ▁ ポン ティ ▁ は ▁ 目 論 ん ▁ で ▁ い ▁ た ▁ 。 ▁『 ▁ 眼 ▁ と ▁ 精神 ▁ 』 ▁( ▁1961 ▁ 年 ▁) ▁ は ▁この ▁「 ▁ 肉 ▁ 」 ▁ の ▁ 概念 ▁ を ▁ 絵 画 ▁ や ▁ 彫 刻 ▁ など ▁ の ▁ 美術 ▁ 作品 ▁ に ▁ 適用 ▁ しよう ▁ と ▁ し ▁ た ▁ 試 み ▁ で ▁ ある ▁ 。 ▁ 実 ▁ は ▁この ▁「 ▁ 肉 ▁ 」 ▁ と ▁ いう ▁ 概念 ▁ は ▁ 、 ▁ メ ル ロ ▁= ▁ ポン ティ ▁ に ▁ 先 立 っ ▁ て ▁ 、 ▁ すでに ▁ サ ル トル ▁ が ▁『 ▁ 存在 ▁ と ▁ 無 ▁ 』 ▁( ▁1943 ▁ 年 ▁) ▁ の ▁ 中 ▁ で ▁ 語 っ ▁ て ▁ い ▁ た ▁ もの ▁ で ▁ ある ▁ 。 ▁ メ ル ロ ▁= ▁ ポン ティ ▁ が ▁その ▁ こと ▁ を ▁ 知 ら ▁ なか っ ▁ た ▁ はず ▁ は ▁ ない ▁ から ▁ 、 ▁ 彼 ▁ は ▁ サ ル トル ▁ の ▁ 哲学 ▁ を ▁ ほぼ ▁ 全面的 ▁ に ▁ 批判 ▁ し ▁ ながら ▁ 、 ▁この ▁ 概念 ▁ の ▁ 有効 性 ▁ を ▁ 認め ▁ 、 ▁ 独自 ▁ の ▁ 存在 論 ▁ 的 ▁ 文 脈 ▁ で ▁ 展開 ▁ し ▁ た ▁ の ▁ だろう ▁ 。 ▁ サ ル トル ▁ の ▁ 場合 ▁ 、 ▁この ▁ 概念 ▁ は ▁ 男女 ▁( ▁ 異 性 ▁) ▁ 間 ▁ の ▁「 ▁ 愛 撫 ▁ 」 ▁ に ▁ おい ▁ て ▁ 、 ▁ 両 者 ▁ の ▁ 身体 ▁ が ▁ 快感 ▁ に ▁ おい ▁ て ▁ 溶 け 合う ▁ よう ▁ に ▁ 結び つく ▁ 状態 ▁ を ▁ 指 し ▁ て ▁ いる ▁ 。 ▁それ ▁ は ▁ 即 自 ▁( ▁ 物 ▁) ▁ と ▁ 対 自 ▁( ▁ 意識 ▁) ▁ 、 ▁ 対 自 ▁( ▁ 自己 ▁ と ▁ の ▁ 関係 ▁) ▁ と ▁ 対 他 ▁( ▁他 者 ▁ と ▁ の ▁ 関係 ▁) ▁ と ▁ いう ▁ サ ル トル ▁ の ▁二 ▁ 元 ▁ 論 ▁ 的 ▁ な ▁ 対 立 ▁ 図 式 ▁ を ▁ 破 る ▁ もの ▁ と ▁ な っ ▁ て ▁ いる ▁ 。 ▁ 加 藤 ▁ 周一 ▁ が ▁この ▁ サ ル トル ▁ の ▁「 ▁ 肉 ▁ 」 ▁ の ▁ 概念 ▁ に ▁ つい ▁ て ▁ 語 っ ▁ て ▁ いる ▁ 箇所 ▁ が ▁ ある ▁ 。 ▁それ ▁ は ▁「 ▁ 絵 ▁ の ▁ なか ▁ の ▁ 女 ▁ たち ▁ 」 ▁- LS B - ▁1 ▁- RS B - ▁ と ▁ いう ▁ 、 ▁ 絵 画 ▁ に ▁ つい ▁ て ▁ の ▁ 随 筆 ▁ に ▁ おい ▁ て ▁ で ▁ ある ▁ 。 ▁この ▁「 ▁ 絵 ▁ の ▁ なか ▁ の ▁ 女 ▁ たち ▁ 」 ▁ は ▁ 、 ▁ い わ ば ▁ 加 藤 ▁ の ▁ 私 的 ▁ 好み ▁( ▁ 趣味 ▁) ▁ に ▁ よ る ▁ 女性 ▁ 肖 像 ▁ 画 論 ▁ 、 ▁ 裸 婦 ▁ 画 論 ▁ で ▁ あり ▁ 、 ▁ ある ▁ 意味 ▁ で ▁ は ▁ 加 藤 ▁ の ▁ エ ロ ティ シ ズ ム ▁ 論 ▁ で ▁ ある ▁ 。 ▁ 歴史 的 ▁ 知名度 ▁ や ▁ 重要性 ▁ が ▁ 配慮 ▁ さ ▁ れ ▁ て ▁ いる ▁ と ▁ は ▁ い え ▁ 、 ▁ そこ ▁ で ▁ 語 ら ▁ れる ▁ 絵 画 ▁ は ▁ 基本 的 ▁ に ▁ 加 藤 ▁ が ▁ 好 む ▁ 作品 ▁ で ▁ あり ▁ 、 ▁ 彼 ▁ が ▁ 感 銘 ▁ を ▁ 受け ▁ た ▁ 作品 ▁ で ▁ ある ▁ と ▁ 見 ▁ て ▁ よい ▁ 。 ▁それ ▁ は ▁お の ず と ▁ 加 藤 ▁ の ▁ 裸 婦 ▁ 像 ▁ あるいは ▁ 女性 ▁ の ▁ 裸 体 ▁ へ ▁ の ▁ 趣味 ▁ 嗜 好 ▁ を ▁ 示 す ▁ もの ▁ で ▁ あり ▁ 、 ▁ つき つ め れ ▁ ば ▁ 一人 ▁ の ▁ 男性 ▁ と ▁ し ▁ て ▁ の ▁ 加 藤 ▁ の ▁ 性的 ▁ 嗜 好 ▁( ▁ 志 向 ▁) ▁ を ▁ か いま 見 ▁ せる ▁ もの ▁ と ▁ な っ ▁ て ▁ いる ▁ 。 ▁ たとえば ▁ 作者 ▁ 不 詳 ▁ の ▁ インド ▁ の ▁ 細 密 ▁ 画 ▁ に ▁ おい ▁ て ▁ 、 ▁ 男性 ▁ が ▁ 膝 ▁ に ▁ 抱 え ▁ た ▁ 女性 ▁ を ▁ 背後 ▁ から ▁ 愛 撫 ▁ し ▁ て ▁ いる ▁ 場面 ▁ を ▁ 描 い ▁ た ▁ 作品 ▁( ▁「 ▁ 男 ▁ の ▁ 右手 ▁ は ▁ 、 ▁ 薄 衣 ▁ の ▁ 上 ▁ から ▁ 女 ▁ の ▁ 乳 ▁ を ▁ 愛 撫 ▁ する ▁ 。 ▁ 〔 ▁ 中 略 ▁ 〕 ▁ 男 ▁ は ▁その ▁ 瞬間 ▁ に ▁ 動 く ▁ 指 先 ▁その ▁ もの ▁ で ▁ ある ▁ 」 ▁( ▁312 ▁) ▁) ▁ 。 ▁ あるいは ▁ ゴ ー ギャ ン ▁ が ▁ 褐 色 ▁ の ▁ 肌 ▁ を ▁ し ▁ た ▁ タ ヒ チ ▁ の ▁ 裸 婦 ▁ を ▁ 描 い ▁ た ▁『 ▁ か ぐ わ し ▁ き ▁ 大地 ▁ 』 ▁( ▁「 ▁ 彼 ▁ が ▁その ▁ 美 ▁ を ▁ 発見 ▁ し ▁ ない ▁ ため ▁ に ▁ は ▁ 、 ▁ タ ヒ ティ ▁ の ▁ ゴ ー ギャ ン ▁ は ▁ 、 ▁ あまり ▁ に ▁ も ▁ 、 ▁その ▁ 肌 ▁ の ▁ 温 か さ ▁ 、 ▁ 微 か ▁ な ▁ 湿 り ▁ 、 ▁ 滑 ら か ▁ さ ▁ と ▁ いう ▁ べ から ▁ ざ る ▁ 弾 力 ▁ を ▁ 、 ▁ 愛 し ▁ て ▁ い ▁ た ▁ の ▁ で ▁ あ ろう ▁ 」 ▁( ▁3 22 ▁) ▁) ▁ 。 ▁ あるいは ▁ クリ ム ト ▁ の ▁『 ▁ ダ ナ エ ▁ 』 ▁( ▁「 ▁その ▁ 腿 ▁ の ▁ 間 ▁ に ▁ 降り そ そ ぎ ▁ 溢 れる ▁ 雨 ▁ を ▁ 受け ▁ て ▁ 、 ▁ 恍 惚 ▁ と ▁ し ▁ て ▁ 眼 ▁ を ▁ 閉 じ ▁ 、 ▁ 半 ば ▁ 口 ▁ を ▁ 開 い ▁ て ▁ 、 ▁ 片 手 ▁ で ▁ 一方 ▁ の ▁ 乳 ▁ を ▁ 押 える ▁ 」 ▁( ▁3 36 ▁) ▁) ▁ 。 ▁ おそらく ▁ こう ▁ し ▁ た ▁ 列 挙 ▁ の ▁ 頂 点 ▁ に ▁ 来る ▁ の ▁ は ▁ 、 ▁ クラ ナ ッ ハ ▁ の ▁『 ▁ ヴェ ヌ ス ▁ 』 ▁ で ▁ あ ろう ▁( ▁「 ▁ 丸 い ▁ 小さな ▁ 乳 ▁ が ▁ 、 ▁ 胸 ▁ の ▁ 上 ▁ の ▁ 方 ▁ に ▁ なら ん ▁ で ▁ い ▁ て ▁ 、 ▁ 細 腰 ▁ から ▁ 下 腹 ▁ に ▁ かけ ▁ て ▁ の ▁ 部分 ▁ が ▁ 長く ▁ 、 ▁ 両 ▁ 肢 ▁ は ▁ 殊 に ▁ 細 長く ▁ て ▁ 、 ▁ 真 直 ぐ ▁ に ▁ 伸び ▁ て ▁ いる ▁ 。 ▁ 細 い ▁ 身体 ▁ の ▁ 全体 ▁ の ▁ なか ▁ で ▁ 、 ▁ 膨 み ▁ の ▁ 目 立つ ▁ ところ ▁ は ▁ 、 ▁ 腹部 ▁ と ▁ 太 腿 ▁ で ▁ ある ▁ 」 ▁( ▁ 347 ▁) ▁) ▁ 。 ▁この ▁ よう ▁ に ▁ 見 ▁ て ▁ くる ▁ と ▁ 、 ▁ 加 藤 ▁ が ▁ 読 者 ▁ に ▁その ▁ 作品 ▁ の ▁ 特徴 ▁ を ▁ 示 そう ▁ と ▁ し ▁ て ▁ 、 ▁また ▁ 読 者 ▁ の ▁ ま な ざ し ▁ を ▁ 作品 ▁ の ▁その ▁ 箇所 ▁ に ▁ 導 こう ▁ と ▁ し ▁ て ▁ 描 く ▁ 描 写 ▁ に ▁ は ▁ 、 ▁ は から ▁ ず ▁ も ▁ 加 藤 ▁ の ▁ 視 線 ▁ と ▁それ ▁ を ▁ 支 える ▁ 欲 情 ▁ を ▁ 示 し ▁ て ▁ いる ▁ よう ▁ に ▁ 思 わ ▁ れる ▁ 。 ▁ つまり ▁「 ▁ 乳 ▁ 」 ▁「 ▁ 弾 力 ▁ 」 ▁「 ▁ 腿 ▁ 」 ▁「 ▁ 下 腹 ▁ 」 ▁... ▁ 。 ▁それ ▁ は ▁ ヴェ ヌ ス ▁ の ▁ 細 い ▁ 首 ▁ や ▁ 、 ▁ 衣 ▁ に ▁ 触れ る ▁ 指 先 ▁ に ▁ は ▁ 向 かわ ▁ ない ▁ 。 ▁それ ▁ ら ▁ は ▁ 曲 線 ▁ を ▁ 示 す ▁「 ▁ 下 腹 ▁ 」 ▁ と ▁ いう ▁ 図 ▁ を ▁ 際 立 た ▁ せる ▁ 地 ▁ の ▁ よう ▁ に ▁ 扱 わ ▁ れ ▁ て ▁ いる ▁ 。 ▁ した が っ ▁ て ▁ 、 ▁ 肩 ▁ や ▁ 背 中 ▁ から ▁ 腰 ▁ に ▁ かけ ▁ て ▁ の ▁ 線 ▁ で ▁ は ▁ なく ▁ て ▁ 、 ▁ 丸 み ▁ を ▁ 帯 び ▁ た ▁「 ▁ 乳 ▁ 」 ▁ 、 ▁また ▁ 、 ▁ 女性 器 ▁ で ▁ は ▁ なく ▁ 太 腿 ▁ 、 ▁ 下 腹 ▁ 。 ▁ そこ ▁ に ▁ は ▁ 丸 み ▁ を ▁ 帯 び ▁ た ▁ 曲 線 ▁ へ ▁ の ▁ 趣味 ▁ が ▁ 現 れ ▁ て ▁ いる ▁( ▁ ク ール ベ ▁ の ▁『 ▁ 世界 ▁ の ▁ 起源 ▁ 』 ▁ は ▁ 、 ▁この ▁ 随 筆 ▁ に ▁ は ▁ 登場 ▁ し ▁ ない ▁) ▁ 。 ▁ もっと も ▁ 、 ▁ 加 藤 ▁ 自身 ▁ は ▁ 十分 ▁ に ▁ 意識 的 ▁ に ▁この ▁ よう ▁ な ▁ 記述 ▁ を ▁ 行 な っ ▁ て ▁ いる ▁ 。 ▁ 次 ▁ の ▁一 ▁ 文 ▁ は ▁ 、 ▁ 加 藤 ▁ が ▁ 視 覚 ▁ の ▁ 内 ▁ で ▁ 感じる ▁ ことが ら ▁ 、 ▁ つまり ▁「 ▁ 見える ▁ もの ▁ 」 ▁ の ▁ 中 ▁ に ▁「 ▁ 触れ ▁ う る ▁ もの ▁ 」 ▁ を ▁ 見る ▁ 感覚 ▁ を ▁ 示 し ▁ て ▁ いる ▁ 。\n",
      "... ...\n",
      "That's great! No error found!\n",
      "All train sample number: 48\n"
     ]
    }
   ],
   "source": [
    "# To check data\n",
    "sent_temp = ''\n",
    "print(\"Checking Data...\")\n",
    "for word_temp in Tr_InputSentences[2]:\n",
    "    sent_temp = sent_temp + ' ' + word_temp\n",
    "print(sent_temp)\n",
    "print('... ...')\n",
    "print(\"That's great! No error found!\")\n",
    "print(\"All train sample number:\", len(Tr_InputSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555fb3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save path depth_mode/Savings\\jp-gcdt-xlm-roberta-base_bs1_seed111\\\\\n",
      "Finetune from path None\n"
     ]
    }
   ],
   "source": [
    "# To save model and data\n",
    "FileName = str(seednumber) + \"_\" + config.tree_infer_mode + '_Batch_' + str(batch_size) + 'Hidden_' + str(hidden_size) + \\\n",
    "            'LR' + str(lr) + \"_\" + str(time.time())\n",
    "\n",
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)\n",
    "print(\"Model save path\", save_path)\n",
    "print(\"Finetune from path\", finetune_frompath)\n",
    "        \n",
    "\n",
    "\"\"\" relation number is set at 42 \"\"\"\n",
    "if \"en-rstdt\" in data_path:\n",
    "    number_of_relations = 42\n",
    "elif \"-gum\" in data_path or \"-gcdt\" in data_path:\n",
    "    number_of_relations = 30\n",
    "model = ParsingNet(language_model, hidden_size, hidden_size,\n",
    "                    hidden_size, atten_model, classifier_input_size, classifier_hidden_size, number_of_relations,\n",
    "                    classifier_bias, rnn_layers, dropout_e, dropout_d, dropout_c, bert_tokenizer=bert_tokenizer)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a15d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch EvalOnly Test:\t26\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7250\t0.5203\t0.4758\n",
      "Epoch EvalOnly Test:\t26\tdocid:\t0\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7158\t0.5579\t0.4737\n",
      "Epoch EvalOnly Test:\t26\tdocid:\t1\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7500\t0.6062\t0.5500\n",
      "Epoch EvalOnly Test:\t26\tdocid:\t2\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.6204\t0.4537\t0.3981\n",
      "Epoch EvalOnly Test:\t26\tdocid:\t3\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7943\t0.5455\t0.4833\n",
      "Epoch EvalOnly Test:\t26\tdocid:\t4\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7137\t0.4824\t0.4706\n",
      "Epoch EvalOnly Test:\t26\tdocid:\t5\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7065\t0.4891\t0.4565\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # reduce memory\n",
    "        # Load model\n",
    "        torchsave_files = sorted(glob.glob(save_path + \"Epoch_*.torchsave\"))\n",
    "        assert len(torchsave_files) == 1\n",
    "        torchsave_best = torchsave_files[0]\n",
    "        best_epoch_Dev = int(re.search(r\"\\d+\", os.path.basename(torchsave_best)).group())\n",
    "            \n",
    "        model.load_state_dict(torch.load(torchsave_best, map_location=device))\n",
    "\n",
    "        # Convert model to eval\n",
    "        model.eval()\n",
    "\n",
    "        # Eval on Testing data\n",
    "        LossTree_Test, LossLabel_Test, span_points_Test, relation_points_Test, \\\n",
    "        nuclearity_points_Test, F1_full_Test, segment_points_Test = getAccuracy(Test_InputSentences,\n",
    "                                                                                Test_EDUBreaks,\n",
    "                                                                                Test_DecoderInput,\n",
    "                                                                                Test_RelationLabel,\n",
    "                                                                                Test_ParsingBreaks,\n",
    "                                                                                Test_GoldenMetric,\n",
    "                                                                                use_pred_segmentation=False,\n",
    "                                                                                use_org_Parseval=use_org_Parseval,\n",
    "                                                                                batch_size=eval_size,\n",
    "                                                                                model=model)\n",
    "        \n",
    "        # Unfold numbers\n",
    "        # Test\n",
    "        P_span_Test, R_span_Test, F_span_Test = span_points_Test\n",
    "        P_relation_Test, R_relation_Test, F_relation_Test = relation_points_Test\n",
    "        P_nuclearity_Test, R_nuclearity_Test, F_nuclearity_Test = nuclearity_points_Test\n",
    "        P_segment_Test, R_segment_Test, F_segment_Test = segment_points_Test\n",
    "        \n",
    "        print('Epoch EvalOnly Test:\\t%d\\n' % best_epoch_Dev,\n",
    "              'F_segment_Test\\tF_span_Test\\tF_nuclearity_Test\\tF_relation_Test:\\n%.4f\\t%.4f\\t%.4f\\t%.4f'\n",
    "              % (F_segment_Test, F_span_Test, F_nuclearity_Test, F_relation_Test))\n",
    "        \n",
    "        # Eval on each document\n",
    "        for docid in range(len(Test_InputSentences)):\n",
    "            LossTree_Test, LossLabel_Test, span_points_Test, relation_points_Test, \\\n",
    "            nuclearity_points_Test, F1_full_Test, segment_points_Test = getAccuracy([Test_InputSentences[docid]],\n",
    "                                                                                    [Test_EDUBreaks[docid]],\n",
    "                                                                                    [Test_DecoderInput[docid]],\n",
    "                                                                                    [Test_RelationLabel[docid]],\n",
    "                                                                                    [Test_ParsingBreaks[docid]],\n",
    "                                                                                    [Test_GoldenMetric[docid]],\n",
    "                                                                                    use_pred_segmentation=False,\n",
    "                                                                                    use_org_Parseval=use_org_Parseval,\n",
    "                                                                                    batch_size=eval_size,\n",
    "                                                                                    model=model)\n",
    "            \n",
    "            # Unfold numbers\n",
    "            # Test\n",
    "            P_span_Test, R_span_Test, F_span_Test = span_points_Test\n",
    "            P_relation_Test, R_relation_Test, F_relation_Test = relation_points_Test\n",
    "            P_nuclearity_Test, R_nuclearity_Test, F_nuclearity_Test = nuclearity_points_Test\n",
    "            P_segment_Test, R_segment_Test, F_segment_Test = segment_points_Test\n",
    "            \n",
    "            print('Epoch EvalOnly Test:\\t%d\\tdocid:\\t%d\\n' % (best_epoch_Dev, docid),\n",
    "                  'F_segment_Test\\tF_span_Test\\tF_nuclearity_Test\\tF_relation_Test:\\n%.4f\\t%.4f\\t%.4f\\t%.4f'\n",
    "                  % (F_segment_Test, F_span_Test, F_nuclearity_Test, F_relation_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5606bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoopNeeded = int(np.ceil(len(Test_EDUBreaks) / batch_size))\n",
    "\n",
    "Loss_tree_all = []\n",
    "Loss_label_all = []\n",
    "correct_span = 0\n",
    "correct_relation = 0\n",
    "correct_nuclearity = 0\n",
    "correct_full = 0\n",
    "no_system = 0\n",
    "no_golden = 0\n",
    "no_gold_seg = 0\n",
    "no_pred_seg = 0\n",
    "no_correct_seg = 0\n",
    "\n",
    "correct_span_list = []\n",
    "correct_relation_list = []\n",
    "correct_nuclearity_list = []\n",
    "no_system_list = []\n",
    "no_golden_list = []\n",
    "\n",
    "all_label_gold = []\n",
    "all_label_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6090593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training import getBatchData\n",
    "\n",
    "with torch.no_grad():\n",
    "    for loop in range(LoopNeeded):\n",
    "        \n",
    "        StartPosition = loop * batch_size\n",
    "        EndPosition = (loop + 1) * batch_size\n",
    "        if EndPosition > len(Test_EDUBreaks):\n",
    "            EndPosition = len(Test_EDUBreaks)\n",
    "\n",
    "        InputSentences_batch, EDUBreaks_batch, _, RelationLabel_batch, ParsingBreaks_batch, GoldenMetric_batch = \\\n",
    "            getBatchData(Test_InputSentences[StartPosition:EndPosition],\n",
    "                         Test_EDUBreaks[StartPosition:EndPosition],\n",
    "                         Test_DecoderInput[StartPosition:EndPosition],\n",
    "                         Test_RelationLabel[StartPosition:EndPosition],\n",
    "                         Test_ParsingBreaks[StartPosition:EndPosition],\n",
    "                         Test_GoldenMetric[StartPosition:EndPosition], batch_size)\n",
    "\n",
    "        Loss_tree_batch, Loss_label_batch, SPAN_batch, Label_Tuple_batch, predict_EDU_breaks = model.TestingLoss(\n",
    "            InputSentences_batch, EDUBreaks_batch, RelationLabel_batch,\n",
    "            ParsingBreaks_batch, GenerateTree=True, use_pred_segmentation=False)\n",
    "\n",
    "        all_label_gold.extend(Label_Tuple_batch[0])\n",
    "        all_label_pred.extend(Label_Tuple_batch[1])\n",
    "\n",
    "        Loss_tree_all.append(Loss_tree_batch)\n",
    "        Loss_label_all.append(Loss_label_batch)\n",
    "\n",
    "        correct_span_batch, correct_relation_batch, correct_nuclearity_batch, correct_full_batch, no_system_batch, no_golden_batch, \\\n",
    "        correct_span_batch_list, correct_relation_batch_list, correct_nuclearity_batch_list, \\\n",
    "        no_system_batch_list, no_golden_batch_list, segment_results_list = getBatchMeasure(SPAN_batch,\n",
    "                                                                                           GoldenMetric_batch,\n",
    "                                                                                           predict_EDU_breaks,\n",
    "                                                                                           EDUBreaks_batch,\n",
    "                                                                                           use_org_Parseval)\n",
    "\n",
    "        correct_span = correct_span + correct_span_batch\n",
    "        correct_relation = correct_relation + correct_relation_batch\n",
    "        correct_nuclearity = correct_nuclearity + correct_nuclearity_batch\n",
    "        correct_full = correct_full + correct_full_batch\n",
    "        no_system = no_system + no_system_batch\n",
    "        no_golden = no_golden + no_golden_batch\n",
    "        no_gold_seg += segment_results_list[0]\n",
    "        no_pred_seg += segment_results_list[1]\n",
    "        no_correct_seg += segment_results_list[2]\n",
    "\n",
    "        correct_span_list += correct_span_batch_list\n",
    "        correct_relation_list += correct_relation_batch_list\n",
    "        correct_nuclearity_list += correct_nuclearity_batch_list\n",
    "        no_system_list += no_system_batch_list\n",
    "        no_golden_list += no_golden_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1133461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_points, relation_points, nuclearity_points, F1_Full, segment_points = getMicroMeasure(correct_span,\n",
    "                                                                                           correct_relation,\n",
    "                                                                                           correct_nuclearity,\n",
    "                                                                                           correct_full,\n",
    "                                                                                           no_system,\n",
    "                                                                                           no_golden,\n",
    "                                                                                           no_gold_seg,\n",
    "                                                                                           no_pred_seg,\n",
    "                                                                                           no_correct_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b7995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Loss_tree, Loss_label, SPAN, Label_Tuple, predict_EDU_breaks = model.TestingLoss(\n",
    "        Test_InputSentences, Test_EDUBreaks, Test_RelationLabel,\n",
    "        Test_ParsingBreaks, GenerateTree=True, use_pred_segmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdac3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_span_1, correct_relation_1, correct_nuclearity_1, correct_full_1, no_system_1, no_golden_1, \\\n",
    "        correct_span_list_1, correct_relation_list_1, correct_nuclearity_list_1, \\\n",
    "        no_system_list_1, no_golden_list_1, segment_results_list_1 = getBatchMeasure(SPAN,\n",
    "                                                                                     Test_GoldenMetric,\n",
    "                                                                                     predict_EDU_breaks,\n",
    "                                                                                     Test_EDUBreaks,\n",
    "                                                                                     use_org_Parseval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e11aa228",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dic_list = []\n",
    "for i in range(len(SPAN)):\n",
    "    predict_dic_list.append(Metric.getEvalData_parseval(SPAN[i][0], predict_EDU_breaks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b03131",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dic_list = []\n",
    "for i in range(len(Test_GoldenMetric)):\n",
    "    gold_dic_list.append(Metric.getEvalData_parseval(Test_GoldenMetric[i][0], Test_EDUBreaks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d542a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dic_list_jp = predict_dic_list[:3]\n",
    "predict_dic_list_gcdt = predict_dic_list[3:]\n",
    "gold_dic_list_jp = gold_dic_list[:3]\n",
    "gold_dic_list_gcdt = gold_dic_list[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cedf999",
   "metadata": {},
   "source": [
    "# Report on Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21cff4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predict_dic_list, gold_dic_list):\n",
    "    \n",
    "    span_correct = 0\n",
    "    nuc_correct = 0\n",
    "    rel_correct = 0\n",
    "    length = 0\n",
    "    \n",
    "    for i in range(len(gold_dic_list)):\n",
    "        length += len(gold_dic_list[i])\n",
    "        for key in gold_dic_list[i].keys():\n",
    "            if key in predict_dic_list[i].keys():\n",
    "                span_correct += 1\n",
    "                if gold_dic_list[i][key][0] == predict_dic_list[i][key][0]:\n",
    "                    rel_correct += 1\n",
    "                if gold_dic_list[i][key][1] == predict_dic_list[i][key][1]:\n",
    "                    nuc_correct += 1\n",
    "    \n",
    "    span = span_correct / length\n",
    "    nuc = nuc_correct / length\n",
    "    rel = rel_correct / length\n",
    "    \n",
    "    return span, nuc, rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5441d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7024793388429752\n",
      "0.5482093663911846\n",
      "0.48484848484848486\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_jp, gold_dic_list_jp)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a7a5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7376543209876543\n",
      "0.5046296296296297\n",
      "0.470679012345679\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_gcdt, gold_dic_list_gcdt)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da8a6c",
   "metadata": {},
   "source": [
    "# Report on Rel Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ac8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_rel_type(predict_dic_list, gold_dic_list):\n",
    "    \n",
    "    relname_accuracy = {}\n",
    "    \n",
    "    for i in range(len(gold_dic_list)):\n",
    "        for key in gold_dic_list[i].keys():\n",
    "            rel = gold_dic_list[i][key][0]\n",
    "            nuc = gold_dic_list[i][key][1]\n",
    "            if rel not in relname_accuracy:\n",
    "                relname_accuracy[rel] = [0, 1]\n",
    "            else:\n",
    "                relname_accuracy[rel][1] += 1\n",
    "            if key in predict_dic_list[i].keys():\n",
    "                if rel == predict_dic_list[i][key][0] and nuc == predict_dic_list[i][key][1]:\n",
    "                    relname_accuracy[rel][0] +=1\n",
    "    \n",
    "    return relname_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a25a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relname_accuracy_jp = report_rel_type(predict_dic_list_jp, gold_dic_list_jp)\n",
    "relname_accuracy_gcdt = report_rel_type(predict_dic_list_gcdt, gold_dic_list_gcdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37fe546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [4, 6],\n",
       " 'elaboration': [40, 76],\n",
       " 'attribution': [4, 6],\n",
       " 'joint': [50, 112],\n",
       " 'context': [2, 27],\n",
       " 'same-unit': [32, 45],\n",
       " 'adversative': [7, 14],\n",
       " 'contingency': [3, 7],\n",
       " 'purpose': [1, 4],\n",
       " 'explanation': [22, 30],\n",
       " 'restatement': [0, 1],\n",
       " 'mode': [5, 10],\n",
       " 'causal': [3, 20],\n",
       " 'evaluation': [0, 4],\n",
       " 'topic': [0, 1]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relname_accuracy_jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ece7883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [16, 39],\n",
       " 'explanation': [11, 41],\n",
       " 'joint': [92, 193],\n",
       " 'elaboration': [60, 99],\n",
       " 'context': [12, 42],\n",
       " 'same-unit': [52, 67],\n",
       " 'mode': [3, 11],\n",
       " 'attribution': [22, 35],\n",
       " 'causal': [6, 47],\n",
       " 'evaluation': [0, 10],\n",
       " 'adversative': [10, 36],\n",
       " 'purpose': [3, 17],\n",
       " 'restatement': [1, 6],\n",
       " 'contingency': [4, 4],\n",
       " 'topic': [0, 1]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relname_accuracy_gcdt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e98764b",
   "metadata": {},
   "source": [
    "# Report on Intra- and Inter-sentential Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "189cd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_seg = []\n",
    "for i in range(len(Test_EDUBreaks)):\n",
    "    doc_sent_seg = []\n",
    "    for index in Test_EDUBreaks[i]:\n",
    "        if Test_InputSentences[i][index] in ['。', '？', '！', '.', '?', '!']:\n",
    "            doc_sent_seg.append(index)\n",
    "    sent_seg.append(doc_sent_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adf7c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_seg_jp = sent_seg[:3]\n",
    "sent_seg_gcdt = sent_seg[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "384867cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_intra(dic_list, sent_seg):\n",
    "    \n",
    "    filtered = []\n",
    "    \n",
    "    for i in range(len(dic_list)):\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        for key in dic_list[i].keys():\n",
    "            start, end = map(int, key.split('-'))\n",
    "            count_in_range = sum(start <= num < end for num in sent_seg[i])\n",
    "            if count_in_range == 0:\n",
    "                result.update({key: dic_list[i][key]})\n",
    "                \n",
    "        filtered.append(result)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c637449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_gold_jp = filter_intra(gold_dic_list_jp, sent_seg_jp)\n",
    "intra_gold_gcdt = filter_intra(gold_dic_list_gcdt, sent_seg_gcdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dd618bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_gold_jp = []\n",
    "inter_gold_gcdt = []\n",
    "\n",
    "for i in range(len(gold_dic_list_jp)):\n",
    "    inter_gold_jp.append({key : value for key, value in gold_dic_list_jp[i].items() if key not in intra_gold_jp[i]})\n",
    "for i in range(len(gold_dic_list_gcdt)):\n",
    "    inter_gold_gcdt.append({key : value for key, value in gold_dic_list_gcdt[i].items() if key not in intra_gold_gcdt[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35df7193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elaboration': [38, 54],\n",
       " 'same-unit': [32, 45],\n",
       " 'joint': [32, 53],\n",
       " 'contingency': [3, 7],\n",
       " 'purpose': [1, 4],\n",
       " 'adversative': [7, 11],\n",
       " 'mode': [5, 10],\n",
       " 'explanation': [20, 21],\n",
       " 'context': [0, 8],\n",
       " 'causal': [3, 12],\n",
       " 'attribution': [3, 4]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list_jp, intra_gold_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c85a8f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': [3, 15],\n",
       " 'organization': [1, 6],\n",
       " 'context': [11, 24],\n",
       " 'same-unit': [52, 67],\n",
       " 'elaboration': [54, 76],\n",
       " 'joint': [62, 102],\n",
       " 'mode': [3, 11],\n",
       " 'attribution': [16, 24],\n",
       " 'causal': [6, 34],\n",
       " 'evaluation': [0, 7],\n",
       " 'adversative': [8, 25],\n",
       " 'purpose': [3, 17],\n",
       " 'restatement': [1, 5],\n",
       " 'contingency': [4, 4],\n",
       " 'topic': [0, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list_gcdt, intra_gold_gcdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44c00863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [4, 6],\n",
       " 'attribution': [1, 2],\n",
       " 'joint': [18, 59],\n",
       " 'context': [2, 19],\n",
       " 'adversative': [0, 3],\n",
       " 'elaboration': [2, 22],\n",
       " 'explanation': [2, 9],\n",
       " 'restatement': [0, 1],\n",
       " 'causal': [0, 8],\n",
       " 'evaluation': [0, 4],\n",
       " 'topic': [0, 1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list_jp, inter_gold_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5fcbc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [15, 33],\n",
       " 'joint': [30, 91],\n",
       " 'explanation': [8, 26],\n",
       " 'elaboration': [6, 23],\n",
       " 'context': [1, 18],\n",
       " 'causal': [0, 13],\n",
       " 'adversative': [2, 11],\n",
       " 'evaluation': [0, 3],\n",
       " 'attribution': [6, 11],\n",
       " 'restatement': [0, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list_gcdt, inter_gold_gcdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "470069fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868995633187773\n",
      "0.7292576419213974\n",
      "0.6419213973799127\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_jp, intra_gold_jp)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c1a6855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8301435406698564\n",
      "0.6028708133971292\n",
      "0.5645933014354066\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_gcdt, intra_gold_gcdt)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f59fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.417910447761194\n",
      "0.23880597014925373\n",
      "0.21641791044776118\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_jp, inter_gold_jp)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7927f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5695652173913044\n",
      "0.32608695652173914\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_gcdt, inter_gold_gcdt)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46a04d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6308539944903582\n",
      "0.6450617283950617\n"
     ]
    }
   ],
   "source": [
    "print(sum(len(doc) for doc in intra_gold_jp) / sum(len(doc) for doc in gold_dic_list_jp))\n",
    "print(sum(len(doc) for doc in intra_gold_gcdt) / sum(len(doc) for doc in gold_dic_list_gcdt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cba62",
   "metadata": {},
   "source": [
    "# Report on Intra-sentential Spans in the Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06ff1fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDUBreaks = []\n",
    "GoldenMetric = []\n",
    "InputSentences = []\n",
    "EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"EDUBreaks.pickle\"), \"rb\")))\n",
    "GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"GoldenLabelforMetric.pickle\"), \"rb\")))\n",
    "InputSentences.extend(pickle.load(open(os.path.join(data_path, \"InputSentences.pickle\"), \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d16caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = []\n",
    "for i in range(len(EDUBreaks)):\n",
    "    doc_sent_seg = []\n",
    "    for index in EDUBreaks[i]:\n",
    "        if InputSentences[i][index] in ['。', '？', '！', '.', '?', '!']:\n",
    "            doc_sent_seg.append(index)\n",
    "    seg.append(doc_sent_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44708bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_jp_all = seg[:30]\n",
    "seg_gcdt_all = seg[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c5d6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dic_list_all = []\n",
    "for i in range(len(GoldenMetric)):\n",
    "    gold_dic_list_all.append(Metric.getEvalData_parseval(GoldenMetric[i][0], EDUBreaks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2eaba41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_jp_all = gold_dic_list_all[:30]\n",
    "gold_gcdt_all = gold_dic_list_all[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2be4d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_jp_all = filter_intra(gold_jp_all, seg_jp_all)\n",
    "intra_gcdt_all = filter_intra(gold_gcdt_all, seg_gcdt_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7de2281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6886212828704842\n",
      "0.6997885835095138\n"
     ]
    }
   ],
   "source": [
    "print(sum(len(doc) for doc in intra_jp_all) / sum(len(doc) for doc in gold_jp_all))\n",
    "print(sum(len(doc) for doc in intra_gcdt_all) / sum(len(doc) for doc in gold_gcdt_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bed7a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dic_jp = defaultdict(int)\n",
    "dic_gcdt = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4cb9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in intra_gcdt_all:\n",
    "    for key in doc.keys():\n",
    "        dic_gcdt[doc[key][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3e89c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'causal': 175,\n",
       "             'context': 247,\n",
       "             'joint': 867,\n",
       "             'explanation': 221,\n",
       "             'same-unit': 729,\n",
       "             'elaboration': 708,\n",
       "             'purpose': 112,\n",
       "             'restatement': 115,\n",
       "             'mode': 112,\n",
       "             'adversative': 181,\n",
       "             'attribution': 315,\n",
       "             'contingency': 60,\n",
       "             'organization': 87,\n",
       "             'evaluation': 42,\n",
       "             'topic': 1})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_gcdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d72a6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dic_gcdt.keys():\n",
    "    dic_gcdt[key] = dic_gcdt[key] / 3972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9aafd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'causal': 0.04405840886203424,\n",
       "             'context': 0.062185297079556896,\n",
       "             'joint': 0.21827794561933533,\n",
       "             'explanation': 0.05563947633434038,\n",
       "             'same-unit': 0.18353474320241692,\n",
       "             'elaboration': 0.1782477341389728,\n",
       "             'purpose': 0.028197381671701913,\n",
       "             'restatement': 0.028952668680765358,\n",
       "             'mode': 0.028197381671701913,\n",
       "             'adversative': 0.045568982880161125,\n",
       "             'attribution': 0.07930513595166164,\n",
       "             'contingency': 0.015105740181268883,\n",
       "             'organization': 0.02190332326283988,\n",
       "             'evaluation': 0.010574018126888218,\n",
       "             'topic': 0.00025176233635448137})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_gcdt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
