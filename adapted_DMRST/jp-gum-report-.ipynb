{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d524e881",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee17ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"\\depth_mode\\Savings\\jp-gum-xlm-roberta-base_bs1_seed111\\\\\"\n",
    "data_path = r\"\\data\\pickle-data\\depth\\to_pt\\jp-gum-xlm-roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ffa6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "import Metric\n",
    "from Metric import getBatchMeasure, getMicroMeasure, getMacroMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca47d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from Training import Train, EvalOnly, getAccuracy\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel, MBart50Tokenizer\n",
    "import config\n",
    "from model_depth import ParsingNet\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config.global_gpu_id)\n",
    "base_path = config.tree_infer_mode + \"_mode/\"\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available() #False\n",
    "device = torch.device(\"cuda:\" + str(config.global_gpu_id) if USE_CUDA else \"cpu\") #device(type='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0a256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "hidden_size = config.hidden_size\n",
    "rnn_layers = 1\n",
    "dropout_e = 0.5\n",
    "dropout_d = 0.5\n",
    "dropout_c = 0.5\n",
    "input_is_word = 'True'\n",
    "atten_model = 'Dotproduct'\n",
    "classifier_input_size = config.hidden_size #768\n",
    "classifier_hidden_size = int(config.hidden_size / 1) #768\n",
    "classifier_bias = 'True'\n",
    "use_org_Parseval = 'True'\n",
    "eval_only = 'True'\n",
    "\n",
    "seednumber = 111\n",
    "data_path_split = [x for x in data_path.split(os.sep) if x != \"\"]\n",
    "data_base = data_path_split[-1]\n",
    "savepath = r\"Savings\\jp-gum-xlm-roberta-base_bs1_seed111\\\\\"\n",
    "finetuning = \"False\"\n",
    "if savepath == None and finetuning == \"True\":\n",
    "    assert False\n",
    "elif savepath == None and finetuning == \"False\":\n",
    "    save_path = base_path + \"Savings/%s_bs%d_seed%d/\" % (data_base, batch_size, seednumber)\n",
    "    finetune_frompath = None\n",
    "elif savepath != None and finetuning == \"True\":\n",
    "    finetune_frompath = base_path + savepath\n",
    "    save_path = finetune_frompath.replace(\"Savings/\", \"Savings/finetuned_\")\n",
    "elif savepath != None and finetuning == \"False\":\n",
    "    finetune_frompath = None\n",
    "    save_path = base_path + savepath\n",
    "        \n",
    "eval_size = 1\n",
    "epoch = 50\n",
    "lr = 0.0002\n",
    "lr_decay_epoch = 1\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27514c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language embedding name:  xlm-roberta-base\n",
      "Language embedding loaded from pretrained:  xlm-roberta-base\n"
     ]
    }
   ],
   "source": [
    "# get language embedding\n",
    "language_embedding_name = re.sub(r\".*jp-\", \"\", re.sub(r\".*gcdt-\", \"\", (re.sub(r\".*rstdt-\", \"\", re.sub(r\".*gum-\", \"\", data_base)))))\n",
    "language_embedding_name = language_embedding_name.replace(\"hfl-\", \"hfl/\").replace(\"SpanBERT-\", \"SpanBERT/\")\n",
    "# 'hfl/chinese-roberta-wwm-ext' a model on Hugging Face\n",
    "\n",
    "\"\"\" BERT tokenizer and model \"\"\"\n",
    "print(\"language embedding name: \", language_embedding_name)\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(language_embedding_name, use_fast=True)\n",
    "bert_model = AutoModel.from_pretrained(language_embedding_name)\n",
    "print(\"Language embedding loaded from pretrained: \", language_embedding_name)\n",
    "\n",
    "\"\"\" freeze some layers \"\"\"\n",
    "for name, param in bert_model.named_parameters():\n",
    "    layer_num = re.findall(\"layer\\.(\\d+)\\.\", name)\n",
    "    if len(layer_num) > 0 and int(layer_num[0]) > 2:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "if USE_CUDA:\n",
    "    language_model = bert_model.cuda()\n",
    "else:\n",
    "    language_model = bert_model\n",
    "\n",
    "# Setting random seeds \n",
    "torch.manual_seed(seednumber)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed_all(seednumber)\n",
    "np.random.seed(seednumber)\n",
    "random.seed(seednumber)\n",
    "\n",
    "# Process bool args       \n",
    "if classifier_bias == 'True':\n",
    "    classifier_bias = True\n",
    "    # True\n",
    "\n",
    "elif classifier_bias == 'False':\n",
    "    classifier_bias = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70233c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr_InputSentences = []\n",
    "Tr_EDUBreaks = []\n",
    "Tr_DecoderInput = []\n",
    "Tr_RelationLabel = []\n",
    "Tr_ParsingBreaks = []\n",
    "Tr_GoldenMetric = []\n",
    "Tr_ParentsIndex = []\n",
    "Tr_SiblingIndex = []\n",
    "\n",
    "Dev_InputSentences = []\n",
    "Dev_EDUBreaks = []\n",
    "Dev_DecoderInput = []\n",
    "Dev_RelationLabel = []\n",
    "Dev_ParsingBreaks = []\n",
    "Dev_GoldenMetric = []\n",
    "Dev_ParentsIndex = []\n",
    "Dev_SiblingIndex = []\n",
    "\n",
    "# Load Testing data\n",
    "Test_InputSentences = []\n",
    "Test_EDUBreaks = []\n",
    "Test_DecoderInput = []\n",
    "Test_RelationLabel = []\n",
    "Test_ParsingBreaks = []\n",
    "Test_GoldenMetric = []\n",
    "\n",
    "# Load Training data\n",
    "Tr_InputSentences.extend(pickle.load(open(os.path.join(data_path, \"Training_InputSentences.pickle\"), \"rb\")))\n",
    "Tr_EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"Training_EDUBreaks.pickle\"), \"rb\")))\n",
    "Tr_DecoderInput.extend(pickle.load(open(os.path.join(data_path, \"Training_DecoderInputs.pickle\"), \"rb\")))\n",
    "Tr_RelationLabel.extend(pickle.load(open(os.path.join(data_path, \"Training_RelationLabel.pickle\"), \"rb\")))\n",
    "Tr_ParsingBreaks.extend(pickle.load(open(os.path.join(data_path, \"Training_ParsingIndex.pickle\"), \"rb\")))\n",
    "Tr_GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"Training_GoldenLabelforMetric.pickle\"), \"rb\")))\n",
    "Tr_ParentsIndex.extend(pickle.load(open(os.path.join(data_path, \"Training_ParentsIndex.pickle\"), \"rb\")))\n",
    "Tr_SiblingIndex.extend(pickle.load(open(os.path.join(data_path, \"Training_Sibling.pickle\"), \"rb\")))\n",
    "\n",
    "# Load Deving data\n",
    "# Dev_InputSentences.extend(pickle.load(open(os.path.join(data_path, \"Deving_InputSentences.pickle\"), \"rb\")))\n",
    "# Dev_EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"Deving_EDUBreaks.pickle\"), \"rb\")))\n",
    "# Dev_DecoderInput.extend(pickle.load(open(os.path.join(data_path, \"Deving_DecoderInputs.pickle\"), \"rb\")))\n",
    "# Dev_RelationLabel.extend(pickle.load(open(os.path.join(data_path, \"Deving_RelationLabel.pickle\"), \"rb\")))\n",
    "# Dev_ParsingBreaks.extend(pickle.load(open(os.path.join(data_path, \"Deving_ParsingIndex.pickle\"), \"rb\")))\n",
    "# Dev_GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"Deving_GoldenLabelforMetric.pickle\"), \"rb\")))\n",
    "# Dev_ParentsIndex.extend(pickle.load(open(os.path.join(data_path, \"Deving_ParentsIndex.pickle\"), \"rb\")))\n",
    "# Dev_SiblingIndex.extend(pickle.load(open(os.path.join(data_path, \"Deving_Sibling.pickle\"), \"rb\")))\n",
    "\n",
    "# Load Testing data\n",
    "Test_InputSentences.extend(pickle.load(open(os.path.join(data_path, \"Testing_InputSentences.pickle\"), \"rb\")))\n",
    "Test_EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"Testing_EDUBreaks.pickle\"), \"rb\")))\n",
    "Test_DecoderInput.extend(pickle.load(open(os.path.join(data_path, \"Testing_DecoderInputs.pickle\"), \"rb\")))\n",
    "Test_RelationLabel.extend(pickle.load(open(os.path.join(data_path, \"Testing_RelationLabel.pickle\"), \"rb\")))\n",
    "Test_ParsingBreaks.extend(pickle.load(open(os.path.join(data_path, \"Testing_ParsingIndex.pickle\"), \"rb\")))\n",
    "Test_GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"Testing_GoldenLabelforMetric.pickle\"), \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28e4503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Data...\n",
      " ▁ 加 藤 ▁ 周一 ▁ の ▁「 ▁ 眼 ▁ 」 ▁ と ▁「 ▁ 耳 ▁ 」 ▁ 加 國 ▁ 尚 志 ▁ メ ル ロ ▁= ▁ ポン ティ ▁ 晩 年 ▁ の ▁ 哲学 ▁ 概念 ▁ に ▁「 ▁ 肉 ▁la ▁chair ▁ 」 ▁ と ▁ いう ▁ 概念 ▁ が ▁ ある ▁ 。 ▁ これ ▁ は ▁ たとえば ▁ 右手 ▁ と ▁ 左 手 ▁ を ▁ 重 ね 合わせ る ▁ とき ▁ 、 ▁ 触れ る ▁ 手 ▁ と ▁ 触れ ▁ られる ▁ 手 ▁ の ▁ 間 ▁ に ▁ 可 逆 ▁ 的 ▁ で ▁ あい まい ▁ な ▁ 感覚 ▁ が ▁ 生 じ ▁ 、 ▁ 主 観 ▁ と ▁ 客 観 ▁ 、 ▁ 能 動 ▁ と ▁ 受 動 ▁ が ▁ 相互 ▁ に ▁ 移 り ▁ 行き あ う ▁ よう ▁ な ▁「 ▁ 感じ ▁ られる ▁ もの ▁le ▁sensible ▁ 」 ▁ を ▁ 言い 表 し ▁ た ▁ もの ▁ で ▁ ある ▁ 。 ▁この ▁「 ▁ 感じ ▁ られる ▁ もの ▁ 」 ▁ は ▁「 ▁ 見える ▁ もの ▁ 」 ▁ や ▁「 ▁ 触れ ▁ う る ▁ もの ▁ 」 ▁ に ▁ 宿 り ▁ 、 ▁ さらに ▁ は ▁それ ▁ ら ▁ 相互 ▁ の ▁ 転 移 ▁ を ▁ 可能 ▁ に ▁ する ▁ 。 ▁この ▁「 ▁ 肉 ▁ 」 ▁ の ▁ 経験 ▁ が ▁ たとえば ▁ 色 ▁ など ▁ の ▁ 質 ▁ の ▁ 経験 ▁ の ▁ 基礎 ▁ に ▁ あり ▁ 、 ▁ 感 性 ▁ 的 ▁ な ▁ 現象 ▁ を ▁ 現象 ▁ と ▁ し ▁ て ▁ 成立 ▁ さ ▁ せる ▁ 存在 論 ▁ 的 ▁ な ▁ 概念 ▁ と ▁ し ▁ て ▁ 主 客 ▁二 ▁ 元 ▁ 論 ▁ の ▁ 近代 ▁ 哲学 的 ▁ 図 式 ▁ を ▁ 解 体 ▁ さ ▁ せる ▁ もの ▁ と ▁ なる ▁ こと ▁ を ▁ メ ル ロ ▁= ▁ ポン ティ ▁ は ▁ 目 論 ん ▁ で ▁ い ▁ た ▁ 。 ▁『 ▁ 眼 ▁ と ▁ 精神 ▁ 』 ▁( ▁1961 ▁ 年 ▁) ▁ は ▁この ▁「 ▁ 肉 ▁ 」 ▁ の ▁ 概念 ▁ を ▁ 絵 画 ▁ や ▁ 彫 刻 ▁ など ▁ の ▁ 美術 ▁ 作品 ▁ に ▁ 適用 ▁ しよう ▁ と ▁ し ▁ た ▁ 試 み ▁ で ▁ ある ▁ 。 ▁ 実 ▁ は ▁この ▁「 ▁ 肉 ▁ 」 ▁ と ▁ いう ▁ 概念 ▁ は ▁ 、 ▁ メ ル ロ ▁= ▁ ポン ティ ▁ に ▁ 先 立 っ ▁ て ▁ 、 ▁ すでに ▁ サ ル トル ▁ が ▁『 ▁ 存在 ▁ と ▁ 無 ▁ 』 ▁( ▁1943 ▁ 年 ▁) ▁ の ▁ 中 ▁ で ▁ 語 っ ▁ て ▁ い ▁ た ▁ もの ▁ で ▁ ある ▁ 。 ▁ メ ル ロ ▁= ▁ ポン ティ ▁ が ▁その ▁ こと ▁ を ▁ 知 ら ▁ なか っ ▁ た ▁ はず ▁ は ▁ ない ▁ から ▁ 、 ▁ 彼 ▁ は ▁ サ ル トル ▁ の ▁ 哲学 ▁ を ▁ ほぼ ▁ 全面的 ▁ に ▁ 批判 ▁ し ▁ ながら ▁ 、 ▁この ▁ 概念 ▁ の ▁ 有効 性 ▁ を ▁ 認め ▁ 、 ▁ 独自 ▁ の ▁ 存在 論 ▁ 的 ▁ 文 脈 ▁ で ▁ 展開 ▁ し ▁ た ▁ の ▁ だろう ▁ 。 ▁ サ ル トル ▁ の ▁ 場合 ▁ 、 ▁この ▁ 概念 ▁ は ▁ 男女 ▁( ▁ 異 性 ▁) ▁ 間 ▁ の ▁「 ▁ 愛 撫 ▁ 」 ▁ に ▁ おい ▁ て ▁ 、 ▁ 両 者 ▁ の ▁ 身体 ▁ が ▁ 快感 ▁ に ▁ おい ▁ て ▁ 溶 け 合う ▁ よう ▁ に ▁ 結び つく ▁ 状態 ▁ を ▁ 指 し ▁ て ▁ いる ▁ 。 ▁それ ▁ は ▁ 即 自 ▁( ▁ 物 ▁) ▁ と ▁ 対 自 ▁( ▁ 意識 ▁) ▁ 、 ▁ 対 自 ▁( ▁ 自己 ▁ と ▁ の ▁ 関係 ▁) ▁ と ▁ 対 他 ▁( ▁他 者 ▁ と ▁ の ▁ 関係 ▁) ▁ と ▁ いう ▁ サ ル トル ▁ の ▁二 ▁ 元 ▁ 論 ▁ 的 ▁ な ▁ 対 立 ▁ 図 式 ▁ を ▁ 破 る ▁ もの ▁ と ▁ な っ ▁ て ▁ いる ▁ 。 ▁ 加 藤 ▁ 周一 ▁ が ▁この ▁ サ ル トル ▁ の ▁「 ▁ 肉 ▁ 」 ▁ の ▁ 概念 ▁ に ▁ つい ▁ て ▁ 語 っ ▁ て ▁ いる ▁ 箇所 ▁ が ▁ ある ▁ 。 ▁それ ▁ は ▁「 ▁ 絵 ▁ の ▁ なか ▁ の ▁ 女 ▁ たち ▁ 」 ▁- LS B - ▁1 ▁- RS B - ▁ と ▁ いう ▁ 、 ▁ 絵 画 ▁ に ▁ つい ▁ て ▁ の ▁ 随 筆 ▁ に ▁ おい ▁ て ▁ で ▁ ある ▁ 。 ▁この ▁「 ▁ 絵 ▁ の ▁ なか ▁ の ▁ 女 ▁ たち ▁ 」 ▁ は ▁ 、 ▁ い わ ば ▁ 加 藤 ▁ の ▁ 私 的 ▁ 好み ▁( ▁ 趣味 ▁) ▁ に ▁ よ る ▁ 女性 ▁ 肖 像 ▁ 画 論 ▁ 、 ▁ 裸 婦 ▁ 画 論 ▁ で ▁ あり ▁ 、 ▁ ある ▁ 意味 ▁ で ▁ は ▁ 加 藤 ▁ の ▁ エ ロ ティ シ ズ ム ▁ 論 ▁ で ▁ ある ▁ 。 ▁ 歴史 的 ▁ 知名度 ▁ や ▁ 重要性 ▁ が ▁ 配慮 ▁ さ ▁ れ ▁ て ▁ いる ▁ と ▁ は ▁ い え ▁ 、 ▁ そこ ▁ で ▁ 語 ら ▁ れる ▁ 絵 画 ▁ は ▁ 基本 的 ▁ に ▁ 加 藤 ▁ が ▁ 好 む ▁ 作品 ▁ で ▁ あり ▁ 、 ▁ 彼 ▁ が ▁ 感 銘 ▁ を ▁ 受け ▁ た ▁ 作品 ▁ で ▁ ある ▁ と ▁ 見 ▁ て ▁ よい ▁ 。 ▁それ ▁ は ▁お の ず と ▁ 加 藤 ▁ の ▁ 裸 婦 ▁ 像 ▁ あるいは ▁ 女性 ▁ の ▁ 裸 体 ▁ へ ▁ の ▁ 趣味 ▁ 嗜 好 ▁ を ▁ 示 す ▁ もの ▁ で ▁ あり ▁ 、 ▁ つき つ め れ ▁ ば ▁ 一人 ▁ の ▁ 男性 ▁ と ▁ し ▁ て ▁ の ▁ 加 藤 ▁ の ▁ 性的 ▁ 嗜 好 ▁( ▁ 志 向 ▁) ▁ を ▁ か いま 見 ▁ せる ▁ もの ▁ と ▁ な っ ▁ て ▁ いる ▁ 。 ▁ たとえば ▁ 作者 ▁ 不 詳 ▁ の ▁ インド ▁ の ▁ 細 密 ▁ 画 ▁ に ▁ おい ▁ て ▁ 、 ▁ 男性 ▁ が ▁ 膝 ▁ に ▁ 抱 え ▁ た ▁ 女性 ▁ を ▁ 背後 ▁ から ▁ 愛 撫 ▁ し ▁ て ▁ いる ▁ 場面 ▁ を ▁ 描 い ▁ た ▁ 作品 ▁( ▁「 ▁ 男 ▁ の ▁ 右手 ▁ は ▁ 、 ▁ 薄 衣 ▁ の ▁ 上 ▁ から ▁ 女 ▁ の ▁ 乳 ▁ を ▁ 愛 撫 ▁ する ▁ 。 ▁ 〔 ▁ 中 略 ▁ 〕 ▁ 男 ▁ は ▁その ▁ 瞬間 ▁ に ▁ 動 く ▁ 指 先 ▁その ▁ もの ▁ で ▁ ある ▁ 」 ▁( ▁312 ▁) ▁) ▁ 。 ▁ あるいは ▁ ゴ ー ギャ ン ▁ が ▁ 褐 色 ▁ の ▁ 肌 ▁ を ▁ し ▁ た ▁ タ ヒ チ ▁ の ▁ 裸 婦 ▁ を ▁ 描 い ▁ た ▁『 ▁ か ぐ わ し ▁ き ▁ 大地 ▁ 』 ▁( ▁「 ▁ 彼 ▁ が ▁その ▁ 美 ▁ を ▁ 発見 ▁ し ▁ ない ▁ ため ▁ に ▁ は ▁ 、 ▁ タ ヒ ティ ▁ の ▁ ゴ ー ギャ ン ▁ は ▁ 、 ▁ あまり ▁ に ▁ も ▁ 、 ▁その ▁ 肌 ▁ の ▁ 温 か さ ▁ 、 ▁ 微 か ▁ な ▁ 湿 り ▁ 、 ▁ 滑 ら か ▁ さ ▁ と ▁ いう ▁ べ から ▁ ざ る ▁ 弾 力 ▁ を ▁ 、 ▁ 愛 し ▁ て ▁ い ▁ た ▁ の ▁ で ▁ あ ろう ▁ 」 ▁( ▁3 22 ▁) ▁) ▁ 。 ▁ あるいは ▁ クリ ム ト ▁ の ▁『 ▁ ダ ナ エ ▁ 』 ▁( ▁「 ▁その ▁ 腿 ▁ の ▁ 間 ▁ に ▁ 降り そ そ ぎ ▁ 溢 れる ▁ 雨 ▁ を ▁ 受け ▁ て ▁ 、 ▁ 恍 惚 ▁ と ▁ し ▁ て ▁ 眼 ▁ を ▁ 閉 じ ▁ 、 ▁ 半 ば ▁ 口 ▁ を ▁ 開 い ▁ て ▁ 、 ▁ 片 手 ▁ で ▁ 一方 ▁ の ▁ 乳 ▁ を ▁ 押 える ▁ 」 ▁( ▁3 36 ▁) ▁) ▁ 。 ▁ おそらく ▁ こう ▁ し ▁ た ▁ 列 挙 ▁ の ▁ 頂 点 ▁ に ▁ 来る ▁ の ▁ は ▁ 、 ▁ クラ ナ ッ ハ ▁ の ▁『 ▁ ヴェ ヌ ス ▁ 』 ▁ で ▁ あ ろう ▁( ▁「 ▁ 丸 い ▁ 小さな ▁ 乳 ▁ が ▁ 、 ▁ 胸 ▁ の ▁ 上 ▁ の ▁ 方 ▁ に ▁ なら ん ▁ で ▁ い ▁ て ▁ 、 ▁ 細 腰 ▁ から ▁ 下 腹 ▁ に ▁ かけ ▁ て ▁ の ▁ 部分 ▁ が ▁ 長く ▁ 、 ▁ 両 ▁ 肢 ▁ は ▁ 殊 に ▁ 細 長く ▁ て ▁ 、 ▁ 真 直 ぐ ▁ に ▁ 伸び ▁ て ▁ いる ▁ 。 ▁ 細 い ▁ 身体 ▁ の ▁ 全体 ▁ の ▁ なか ▁ で ▁ 、 ▁ 膨 み ▁ の ▁ 目 立つ ▁ ところ ▁ は ▁ 、 ▁ 腹部 ▁ と ▁ 太 腿 ▁ で ▁ ある ▁ 」 ▁( ▁ 347 ▁) ▁) ▁ 。 ▁この ▁ よう ▁ に ▁ 見 ▁ て ▁ くる ▁ と ▁ 、 ▁ 加 藤 ▁ が ▁ 読 者 ▁ に ▁その ▁ 作品 ▁ の ▁ 特徴 ▁ を ▁ 示 そう ▁ と ▁ し ▁ て ▁ 、 ▁また ▁ 読 者 ▁ の ▁ ま な ざ し ▁ を ▁ 作品 ▁ の ▁その ▁ 箇所 ▁ に ▁ 導 こう ▁ と ▁ し ▁ て ▁ 描 く ▁ 描 写 ▁ に ▁ は ▁ 、 ▁ は から ▁ ず ▁ も ▁ 加 藤 ▁ の ▁ 視 線 ▁ と ▁それ ▁ を ▁ 支 える ▁ 欲 情 ▁ を ▁ 示 し ▁ て ▁ いる ▁ よう ▁ に ▁ 思 わ ▁ れる ▁ 。 ▁ つまり ▁「 ▁ 乳 ▁ 」 ▁「 ▁ 弾 力 ▁ 」 ▁「 ▁ 腿 ▁ 」 ▁「 ▁ 下 腹 ▁ 」 ▁... ▁ 。 ▁それ ▁ は ▁ ヴェ ヌ ス ▁ の ▁ 細 い ▁ 首 ▁ や ▁ 、 ▁ 衣 ▁ に ▁ 触れ る ▁ 指 先 ▁ に ▁ は ▁ 向 かわ ▁ ない ▁ 。 ▁それ ▁ ら ▁ は ▁ 曲 線 ▁ を ▁ 示 す ▁「 ▁ 下 腹 ▁ 」 ▁ と ▁ いう ▁ 図 ▁ を ▁ 際 立 た ▁ せる ▁ 地 ▁ の ▁ よう ▁ に ▁ 扱 わ ▁ れ ▁ て ▁ いる ▁ 。 ▁ した が っ ▁ て ▁ 、 ▁ 肩 ▁ や ▁ 背 中 ▁ から ▁ 腰 ▁ に ▁ かけ ▁ て ▁ の ▁ 線 ▁ で ▁ は ▁ なく ▁ て ▁ 、 ▁ 丸 み ▁ を ▁ 帯 び ▁ た ▁「 ▁ 乳 ▁ 」 ▁ 、 ▁また ▁ 、 ▁ 女性 器 ▁ で ▁ は ▁ なく ▁ 太 腿 ▁ 、 ▁ 下 腹 ▁ 。 ▁ そこ ▁ に ▁ は ▁ 丸 み ▁ を ▁ 帯 び ▁ た ▁ 曲 線 ▁ へ ▁ の ▁ 趣味 ▁ が ▁ 現 れ ▁ て ▁ いる ▁( ▁ ク ール ベ ▁ の ▁『 ▁ 世界 ▁ の ▁ 起源 ▁ 』 ▁ は ▁ 、 ▁この ▁ 随 筆 ▁ に ▁ は ▁ 登場 ▁ し ▁ ない ▁) ▁ 。 ▁ もっと も ▁ 、 ▁ 加 藤 ▁ 自身 ▁ は ▁ 十分 ▁ に ▁ 意識 的 ▁ に ▁この ▁ よう ▁ な ▁ 記述 ▁ を ▁ 行 な っ ▁ て ▁ いる ▁ 。 ▁ 次 ▁ の ▁一 ▁ 文 ▁ は ▁ 、 ▁ 加 藤 ▁ が ▁ 視 覚 ▁ の ▁ 内 ▁ で ▁ 感じる ▁ ことが ら ▁ 、 ▁ つまり ▁「 ▁ 見える ▁ もの ▁ 」 ▁ の ▁ 中 ▁ に ▁「 ▁ 触れ ▁ う る ▁ もの ▁ 」 ▁ を ▁ 見る ▁ 感覚 ▁ を ▁ 示 し ▁ て ▁ いる ▁ 。\n",
      "... ...\n",
      "That's great! No error found!\n",
      "All train sample number: 48\n"
     ]
    }
   ],
   "source": [
    "# To check data\n",
    "sent_temp = ''\n",
    "print(\"Checking Data...\")\n",
    "for word_temp in Tr_InputSentences[2]:\n",
    "    sent_temp = sent_temp + ' ' + word_temp\n",
    "print(sent_temp)\n",
    "print('... ...')\n",
    "print(\"That's great! No error found!\")\n",
    "print(\"All train sample number:\", len(Tr_InputSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555fb3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save path depth_mode/Savings\\jp-gum-xlm-roberta-base_bs1_seed111\\\\\n",
      "Finetune from path None\n"
     ]
    }
   ],
   "source": [
    "# To save model and data\n",
    "FileName = str(seednumber) + \"_\" + config.tree_infer_mode + '_Batch_' + str(batch_size) + 'Hidden_' + str(hidden_size) + \\\n",
    "            'LR' + str(lr) + \"_\" + str(time.time())\n",
    "\n",
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)\n",
    "print(\"Model save path\", save_path)\n",
    "print(\"Finetune from path\", finetune_frompath)\n",
    "        \n",
    "\n",
    "\"\"\" relation number is set at 42 \"\"\"\n",
    "if \"en-rstdt\" in data_path:\n",
    "    number_of_relations = 42\n",
    "elif \"-gum\" in data_path or \"-gcdt\" in data_path:\n",
    "    number_of_relations = 30\n",
    "model = ParsingNet(language_model, hidden_size, hidden_size,\n",
    "                    hidden_size, atten_model, classifier_input_size, classifier_hidden_size, number_of_relations,\n",
    "                    classifier_bias, rnn_layers, dropout_e, dropout_d, dropout_c, bert_tokenizer=bert_tokenizer)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a15d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch EvalOnly Test:\t48\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.6719\t0.5165\t0.4518\n",
      "Epoch EvalOnly Test:\t48\tdocid:\t0\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7263\t0.5368\t0.4737\n",
      "Epoch EvalOnly Test:\t48\tdocid:\t1\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7000\t0.5625\t0.5000\n",
      "Epoch EvalOnly Test:\t48\tdocid:\t2\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.7266\t0.5827\t0.4964\n",
      "Epoch EvalOnly Test:\t48\tdocid:\t3\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.5000\t0.3429\t0.2571\n",
      "Epoch EvalOnly Test:\t48\tdocid:\t4\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.6504\t0.5285\t0.4878\n",
      "Epoch EvalOnly Test:\t48\tdocid:\t5\n",
      " F_segment_Test\tF_span_Test\tF_nuclearity_Test\tF_relation_Test:\n",
      "1.0000\t0.6481\t0.4444\t0.3889\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # reduce memory\n",
    "        # Load model\n",
    "        torchsave_files = sorted(glob.glob(save_path + \"Epoch_*.torchsave\"))\n",
    "        assert len(torchsave_files) == 1\n",
    "        torchsave_best = torchsave_files[0]\n",
    "        best_epoch_Dev = int(re.search(r\"\\d+\", os.path.basename(torchsave_best)).group())\n",
    "            \n",
    "        model.load_state_dict(torch.load(torchsave_best, map_location=device))\n",
    "\n",
    "        # Convert model to eval\n",
    "        model.eval()\n",
    "\n",
    "        # Eval on Testing data\n",
    "        LossTree_Test, LossLabel_Test, span_points_Test, relation_points_Test, \\\n",
    "        nuclearity_points_Test, F1_full_Test, segment_points_Test = getAccuracy(Test_InputSentences,\n",
    "                                                                                Test_EDUBreaks,\n",
    "                                                                                Test_DecoderInput,\n",
    "                                                                                Test_RelationLabel,\n",
    "                                                                                Test_ParsingBreaks,\n",
    "                                                                                Test_GoldenMetric,\n",
    "                                                                                use_pred_segmentation=False,\n",
    "                                                                                use_org_Parseval=use_org_Parseval,\n",
    "                                                                                batch_size=eval_size,\n",
    "                                                                                model=model)\n",
    "        \n",
    "        # Unfold numbers\n",
    "        # Test\n",
    "        P_span_Test, R_span_Test, F_span_Test = span_points_Test\n",
    "        P_relation_Test, R_relation_Test, F_relation_Test = relation_points_Test\n",
    "        P_nuclearity_Test, R_nuclearity_Test, F_nuclearity_Test = nuclearity_points_Test\n",
    "        P_segment_Test, R_segment_Test, F_segment_Test = segment_points_Test\n",
    "        \n",
    "        print('Epoch EvalOnly Test:\\t%d\\n' % best_epoch_Dev,\n",
    "              'F_segment_Test\\tF_span_Test\\tF_nuclearity_Test\\tF_relation_Test:\\n%.4f\\t%.4f\\t%.4f\\t%.4f'\n",
    "              % (F_segment_Test, F_span_Test, F_nuclearity_Test, F_relation_Test))\n",
    "        \n",
    "        # Eval on each document\n",
    "        for docid in range(len(Test_InputSentences)):\n",
    "            LossTree_Test, LossLabel_Test, span_points_Test, relation_points_Test, \\\n",
    "            nuclearity_points_Test, F1_full_Test, segment_points_Test = getAccuracy([Test_InputSentences[docid]],\n",
    "                                                                                    [Test_EDUBreaks[docid]],\n",
    "                                                                                    [Test_DecoderInput[docid]],\n",
    "                                                                                    [Test_RelationLabel[docid]],\n",
    "                                                                                    [Test_ParsingBreaks[docid]],\n",
    "                                                                                    [Test_GoldenMetric[docid]],\n",
    "                                                                                    use_pred_segmentation=False,\n",
    "                                                                                    use_org_Parseval=use_org_Parseval,\n",
    "                                                                                    batch_size=eval_size,\n",
    "                                                                                    model=model)\n",
    "            \n",
    "            # Unfold numbers\n",
    "            # Test\n",
    "            P_span_Test, R_span_Test, F_span_Test = span_points_Test\n",
    "            P_relation_Test, R_relation_Test, F_relation_Test = relation_points_Test\n",
    "            P_nuclearity_Test, R_nuclearity_Test, F_nuclearity_Test = nuclearity_points_Test\n",
    "            P_segment_Test, R_segment_Test, F_segment_Test = segment_points_Test\n",
    "            \n",
    "            print('Epoch EvalOnly Test:\\t%d\\tdocid:\\t%d\\n' % (best_epoch_Dev, docid),\n",
    "                  'F_segment_Test\\tF_span_Test\\tF_nuclearity_Test\\tF_relation_Test:\\n%.4f\\t%.4f\\t%.4f\\t%.4f'\n",
    "                  % (F_segment_Test, F_span_Test, F_nuclearity_Test, F_relation_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5606bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoopNeeded = int(np.ceil(len(Test_EDUBreaks) / batch_size))\n",
    "\n",
    "Loss_tree_all = []\n",
    "Loss_label_all = []\n",
    "correct_span = 0\n",
    "correct_relation = 0\n",
    "correct_nuclearity = 0\n",
    "correct_full = 0\n",
    "no_system = 0\n",
    "no_golden = 0\n",
    "no_gold_seg = 0\n",
    "no_pred_seg = 0\n",
    "no_correct_seg = 0\n",
    "\n",
    "correct_span_list = []\n",
    "correct_relation_list = []\n",
    "correct_nuclearity_list = []\n",
    "no_system_list = []\n",
    "no_golden_list = []\n",
    "\n",
    "all_label_gold = []\n",
    "all_label_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6090593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training import getBatchData\n",
    "\n",
    "with torch.no_grad():\n",
    "    for loop in range(LoopNeeded):\n",
    "        \n",
    "        StartPosition = loop * batch_size\n",
    "        EndPosition = (loop + 1) * batch_size\n",
    "        if EndPosition > len(Test_EDUBreaks):\n",
    "            EndPosition = len(Test_EDUBreaks)\n",
    "\n",
    "        InputSentences_batch, EDUBreaks_batch, _, RelationLabel_batch, ParsingBreaks_batch, GoldenMetric_batch = \\\n",
    "            getBatchData(Test_InputSentences[StartPosition:EndPosition],\n",
    "                         Test_EDUBreaks[StartPosition:EndPosition],\n",
    "                         Test_DecoderInput[StartPosition:EndPosition],\n",
    "                         Test_RelationLabel[StartPosition:EndPosition],\n",
    "                         Test_ParsingBreaks[StartPosition:EndPosition],\n",
    "                         Test_GoldenMetric[StartPosition:EndPosition], batch_size)\n",
    "\n",
    "        Loss_tree_batch, Loss_label_batch, SPAN_batch, Label_Tuple_batch, predict_EDU_breaks = model.TestingLoss(\n",
    "            InputSentences_batch, EDUBreaks_batch, RelationLabel_batch,\n",
    "            ParsingBreaks_batch, GenerateTree=True, use_pred_segmentation=False)\n",
    "\n",
    "        all_label_gold.extend(Label_Tuple_batch[0])\n",
    "        all_label_pred.extend(Label_Tuple_batch[1])\n",
    "\n",
    "        Loss_tree_all.append(Loss_tree_batch)\n",
    "        Loss_label_all.append(Loss_label_batch)\n",
    "\n",
    "        correct_span_batch, correct_relation_batch, correct_nuclearity_batch, correct_full_batch, no_system_batch, no_golden_batch, \\\n",
    "        correct_span_batch_list, correct_relation_batch_list, correct_nuclearity_batch_list, \\\n",
    "        no_system_batch_list, no_golden_batch_list, segment_results_list = getBatchMeasure(SPAN_batch,\n",
    "                                                                                           GoldenMetric_batch,\n",
    "                                                                                           predict_EDU_breaks,\n",
    "                                                                                           EDUBreaks_batch,\n",
    "                                                                                           use_org_Parseval)\n",
    "\n",
    "        correct_span = correct_span + correct_span_batch\n",
    "        correct_relation = correct_relation + correct_relation_batch\n",
    "        correct_nuclearity = correct_nuclearity + correct_nuclearity_batch\n",
    "        correct_full = correct_full + correct_full_batch\n",
    "        no_system = no_system + no_system_batch\n",
    "        no_golden = no_golden + no_golden_batch\n",
    "        no_gold_seg += segment_results_list[0]\n",
    "        no_pred_seg += segment_results_list[1]\n",
    "        no_correct_seg += segment_results_list[2]\n",
    "\n",
    "        correct_span_list += correct_span_batch_list\n",
    "        correct_relation_list += correct_relation_batch_list\n",
    "        correct_nuclearity_list += correct_nuclearity_batch_list\n",
    "        no_system_list += no_system_batch_list\n",
    "        no_golden_list += no_golden_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1133461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_points, relation_points, nuclearity_points, F1_Full, segment_points = getMicroMeasure(correct_span,\n",
    "                                                                                           correct_relation,\n",
    "                                                                                           correct_nuclearity,\n",
    "                                                                                           correct_full,\n",
    "                                                                                           no_system,\n",
    "                                                                                           no_golden,\n",
    "                                                                                           no_gold_seg,\n",
    "                                                                                           no_pred_seg,\n",
    "                                                                                           no_correct_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b7995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    Loss_tree, Loss_label, SPAN, Label_Tuple, predict_EDU_breaks = model.TestingLoss(\n",
    "        Test_InputSentences, Test_EDUBreaks, Test_RelationLabel,\n",
    "        Test_ParsingBreaks, GenerateTree=True, use_pred_segmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdac3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_span_1, correct_relation_1, correct_nuclearity_1, correct_full_1, no_system_1, no_golden_1, \\\n",
    "        correct_span_list_1, correct_relation_list_1, correct_nuclearity_list_1, \\\n",
    "        no_system_list_1, no_golden_list_1, segment_results_list_1 = getBatchMeasure(SPAN,\n",
    "                                                                                     Test_GoldenMetric,\n",
    "                                                                                     predict_EDU_breaks,\n",
    "                                                                                     Test_EDUBreaks,\n",
    "                                                                                     use_org_Parseval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e11aa228",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dic_list = []\n",
    "for i in range(len(SPAN)):\n",
    "    predict_dic_list.append(Metric.getEvalData_parseval(SPAN[i][0], predict_EDU_breaks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b03131",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dic_list = []\n",
    "for i in range(len(Test_GoldenMetric)):\n",
    "    gold_dic_list.append(Metric.getEvalData_parseval(Test_GoldenMetric[i][0], Test_EDUBreaks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c80b9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dic_list_jp = [predict_dic_list[0], predict_dic_list[1], predict_dic_list[5]]\n",
    "gold_dic_list_jp = [gold_dic_list[0], gold_dic_list[1], gold_dic_list[5]]\n",
    "predict_dic_list_gum = predict_dic_list[2:5]\n",
    "gold_dic_list_gum = gold_dic_list[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778022ab",
   "metadata": {},
   "source": [
    "# Report on Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21cff4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predict_dic_list, gold_dic_list):\n",
    "    \n",
    "    span_correct = 0\n",
    "    nuc_correct = 0\n",
    "    rel_correct = 0\n",
    "    length = 0\n",
    "    \n",
    "    for i in range(len(gold_dic_list)):\n",
    "        length += len(gold_dic_list[i])\n",
    "        for key in gold_dic_list[i].keys():\n",
    "            if key in predict_dic_list[i].keys():\n",
    "                span_correct += 1\n",
    "                if gold_dic_list[i][key][0] == predict_dic_list[i][key][0]:\n",
    "                    rel_correct += 1\n",
    "                if gold_dic_list[i][key][1] == predict_dic_list[i][key][1]:\n",
    "                    nuc_correct += 1\n",
    "    \n",
    "    span = span_correct / length\n",
    "    nuc = nuc_correct / length\n",
    "    rel = rel_correct / length\n",
    "    \n",
    "    return span, nuc, rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5441d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6914600550964187\n",
      "0.5206611570247934\n",
      "0.46005509641873277\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_jp, gold_dic_list_jp)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a7a5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6506024096385542\n",
      "0.5120481927710844\n",
      "0.4427710843373494\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_gum, gold_dic_list_gum)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a9472",
   "metadata": {},
   "source": [
    "# Report on Rel Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ac8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_rel_type(predict_dic_list, gold_dic_list):\n",
    "    \n",
    "    relname_accuracy = {}\n",
    "    \n",
    "    for i in range(len(gold_dic_list)):\n",
    "        for key in gold_dic_list[i].keys():\n",
    "            rel = gold_dic_list[i][key][0]\n",
    "            nuc = gold_dic_list[i][key][1]\n",
    "            if rel not in relname_accuracy:\n",
    "                relname_accuracy[rel] = [0, 1]\n",
    "            else:\n",
    "                relname_accuracy[rel][1] += 1\n",
    "            if key in predict_dic_list[i].keys():\n",
    "                if rel == predict_dic_list[i][key][0] and nuc == predict_dic_list[i][key][1]:\n",
    "                    relname_accuracy[rel][0] +=1\n",
    "    \n",
    "    return relname_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a25a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relname_accuracy_jp = report_rel_type(predict_dic_list_jp, gold_dic_list_jp)\n",
    "relname_accuracy_gum = report_rel_type(predict_dic_list_gum, gold_dic_list_gum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37fe546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [3, 6],\n",
       " 'elaboration': [38, 76],\n",
       " 'attribution': [4, 6],\n",
       " 'joint': [48, 112],\n",
       " 'context': [3, 27],\n",
       " 'same-unit': [30, 45],\n",
       " 'adversative': [7, 14],\n",
       " 'contingency': [3, 7],\n",
       " 'purpose': [0, 4],\n",
       " 'explanation': [22, 30],\n",
       " 'restatement': [0, 1],\n",
       " 'mode': [4, 10],\n",
       " 'causal': [3, 20],\n",
       " 'evaluation': [0, 4],\n",
       " 'topic': [0, 1]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relname_accuracy_jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ece7883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [13, 20],\n",
       " 'elaboration': [52, 91],\n",
       " 'joint': [17, 59],\n",
       " 'context': [3, 27],\n",
       " 'adversative': [3, 17],\n",
       " 'explanation': [13, 31],\n",
       " 'purpose': [9, 11],\n",
       " 'mode': [4, 9],\n",
       " 'same-unit': [19, 27],\n",
       " 'attribution': [6, 14],\n",
       " 'causal': [1, 13],\n",
       " 'restatement': [3, 6],\n",
       " 'evaluation': [1, 7]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relname_accuracy_gum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a256ae",
   "metadata": {},
   "source": [
    "# Report on Intra- and Inter-sentential Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14f8d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_seg = []\n",
    "for i in range(len(Test_EDUBreaks)):\n",
    "    doc_sent_seg = []\n",
    "    for index in Test_EDUBreaks[i]:\n",
    "        if Test_InputSentences[i][index] in ['。', '？', '！', '.', '?', '!']:\n",
    "            doc_sent_seg.append(index)\n",
    "    sent_seg.append(doc_sent_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c9c7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_seg_jp = [sent_seg[0], sent_seg[1], sent_seg[5]]\n",
    "sent_seg_gum = sent_seg[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "650862f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_intra(dic_list, sent_seg):\n",
    "    \n",
    "    filtered = []\n",
    "    \n",
    "    for i in range(len(dic_list)):\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        for key in dic_list[i].keys():\n",
    "            start, end = map(int, key.split('-'))\n",
    "            count_in_range = sum(start <= num < end for num in sent_seg[i])\n",
    "            if count_in_range == 0:\n",
    "                result.update({key: dic_list[i][key]})\n",
    "                \n",
    "        filtered.append(result)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9ae04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_gold_jp = filter_intra(gold_dic_list_jp, sent_seg_jp)\n",
    "intra_gold_gum = filter_intra(gold_dic_list_gum, sent_seg_gum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57756077",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_gold_jp = []\n",
    "inter_gold_gum = []\n",
    "\n",
    "for i in range(len(gold_dic_list_jp)):\n",
    "    inter_gold_jp.append({key : value for key, value in gold_dic_list_jp[i].items() if key not in intra_gold_jp[i]})\n",
    "for i in range(len(gold_dic_list_gum)):\n",
    "    inter_gold_gum.append({key : value for key, value in gold_dic_list_gum[i].items() if key not in intra_gold_gum[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b288d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elaboration': [36, 54],\n",
       " 'same-unit': [30, 45],\n",
       " 'joint': [30, 53],\n",
       " 'contingency': [3, 7],\n",
       " 'purpose': [0, 4],\n",
       " 'adversative': [7, 11],\n",
       " 'mode': [4, 10],\n",
       " 'explanation': [20, 21],\n",
       " 'context': [0, 8],\n",
       " 'causal': [3, 12],\n",
       " 'attribution': [3, 4]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list_jp, intra_gold_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d40aae27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elaboration': [47, 62],\n",
       " 'explanation': [7, 14],\n",
       " 'purpose': [8, 10],\n",
       " 'mode': [4, 9],\n",
       " 'same-unit': [19, 27],\n",
       " 'attribution': [2, 7],\n",
       " 'organization': [6, 9],\n",
       " 'joint': [5, 18],\n",
       " 'causal': [1, 7],\n",
       " 'adversative': [3, 11],\n",
       " 'restatement': [3, 5],\n",
       " 'context': [3, 15],\n",
       " 'evaluation': [0, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list_gum, intra_gold_gum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9156b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [3, 6],\n",
       " 'attribution': [1, 2],\n",
       " 'joint': [18, 59],\n",
       " 'context': [3, 19],\n",
       " 'adversative': [0, 3],\n",
       " 'elaboration': [2, 22],\n",
       " 'explanation': [2, 9],\n",
       " 'restatement': [0, 1],\n",
       " 'causal': [0, 8],\n",
       " 'evaluation': [0, 4],\n",
       " 'topic': [0, 1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list_jp, inter_gold_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27dd1aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization': [7, 11],\n",
       " 'joint': [12, 41],\n",
       " 'context': [0, 12],\n",
       " 'adversative': [0, 6],\n",
       " 'explanation': [6, 17],\n",
       " 'elaboration': [5, 29],\n",
       " 'purpose': [1, 1],\n",
       " 'causal': [0, 6],\n",
       " 'evaluation': [1, 6],\n",
       " 'attribution': [4, 7],\n",
       " 'restatement': [0, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_rel_type(predict_dic_list_gum, inter_gold_gum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76a7cc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8427947598253275\n",
      "0.6943231441048034\n",
      "0.6026200873362445\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_jp, intra_gold_jp)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21e9463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.6512820512820513\n",
      "0.5692307692307692\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_gum, intra_gold_gum)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6894e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43283582089552236\n",
      "0.22388059701492538\n",
      "0.21641791044776118\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_jp, inter_gold_jp)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53169089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43795620437956206\n",
      "0.31386861313868614\n",
      "0.26277372262773724\n"
     ]
    }
   ],
   "source": [
    "span, nuc, rel = get_accuracy(predict_dic_list_gum, inter_gold_gum)\n",
    "print(span)\n",
    "print(nuc)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2604333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6308539944903582\n",
      "0.5873493975903614\n"
     ]
    }
   ],
   "source": [
    "print(sum(len(doc) for doc in intra_gold_jp) / sum(len(doc) for doc in gold_dic_list_jp))\n",
    "print(sum(len(doc) for doc in intra_gold_gum) / sum(len(doc) for doc in gold_dic_list_gum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ca4ee",
   "metadata": {},
   "source": [
    "# Report on Intra-sentential Spans in the Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd247cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDUBreaks = []\n",
    "GoldenMetric = []\n",
    "InputSentences = []\n",
    "EDUBreaks.extend(pickle.load(open(os.path.join(data_path, \"EDUBreaks.pickle\"), \"rb\")))\n",
    "GoldenMetric.extend(pickle.load(open(os.path.join(data_path, \"GoldenLabelforMetric.pickle\"), \"rb\")))\n",
    "InputSentences.extend(pickle.load(open(os.path.join(data_path, \"InputSentences.pickle\"), \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6929aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = []\n",
    "for i in range(len(EDUBreaks)):\n",
    "    doc_sent_seg = []\n",
    "    for index in EDUBreaks[i]:\n",
    "        if InputSentences[i][index] in ['。', '？', '！', '.', '?', '!']:\n",
    "            doc_sent_seg.append(index)\n",
    "    seg.append(doc_sent_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a72115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_jp_all = seg[:20] + seg[50:]\n",
    "seg_gum_all = seg[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e08eebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dic_list_all = []\n",
    "for i in range(len(GoldenMetric)):\n",
    "    gold_dic_list_all.append(Metric.getEvalData_parseval(GoldenMetric[i][0], EDUBreaks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a850664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_jp_all = gold_dic_list_all[:20] + gold_dic_list_all[50:]\n",
    "gold_gum_all = gold_dic_list_all[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09487dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_jp_all = filter_intra(gold_jp_all, seg_jp_all)\n",
    "intra_gum_all = filter_intra(gold_gum_all, seg_gum_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a3e677c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6886212828704842\n",
      "0.6375\n"
     ]
    }
   ],
   "source": [
    "print(sum(len(doc) for doc in intra_jp_all) / sum(len(doc) for doc in gold_jp_all))\n",
    "print(sum(len(doc) for doc in intra_gum_all) / sum(len(doc) for doc in gold_gum_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b34a2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'15-38': ['elaboration', 'NS'],\n",
       " '114-162': ['adversative', 'SN'],\n",
       " '126-162': ['context', 'SN'],\n",
       " '233-311': ['same-unit', 'NN'],\n",
       " '256-311': ['elaboration', 'SN'],\n",
       " '256-302': ['mode', 'SN'],\n",
       " '256-271': ['elaboration', 'SN'],\n",
       " '347-391': ['mode', 'SN'],\n",
       " '441-499': ['same-unit', 'NN'],\n",
       " '463-499': ['mode', 'SN'],\n",
       " '463-481': ['elaboration', 'SN'],\n",
       " '505-612': ['same-unit', 'NN'],\n",
       " '556-612': ['mode', 'SN'],\n",
       " '556-578': ['joint', 'NN'],\n",
       " '657-720': ['elaboration', 'SN'],\n",
       " '657-686': ['elaboration', 'SN'],\n",
       " '865-906': ['joint', 'NN'],\n",
       " '925-1001': ['adversative', 'SN'],\n",
       " '925-977': ['explanation', 'NS'],\n",
       " '925-966': ['same-unit', 'NN'],\n",
       " '956-966': ['elaboration', 'SN'],\n",
       " '993-1001': ['elaboration', 'SN'],\n",
       " '1047-1219': ['adversative', 'NN'],\n",
       " '1047-1060': ['elaboration', 'SN'],\n",
       " '1092-1219': ['same-unit', 'NN'],\n",
       " '1092-1122': ['explanation', 'NS'],\n",
       " '1092-1113': ['elaboration', 'SN'],\n",
       " '1092-1102': ['attribution', 'NS'],\n",
       " '1126-1219': ['same-unit', 'NN'],\n",
       " '1150-1219': ['same-unit', 'NN'],\n",
       " '1150-1211': ['explanation', 'NS'],\n",
       " '1150-1202': ['elaboration', 'SN'],\n",
       " '1150-1192': ['joint', 'NN'],\n",
       " '1183-1192': ['attribution', 'NS'],\n",
       " '1283-1362': ['adversative', 'SN'],\n",
       " '1309-1362': ['attribution', 'NS'],\n",
       " '1309-1335': ['joint', 'NN'],\n",
       " '1402-1488': ['adversative', 'SN'],\n",
       " '1402-1439': ['mode', 'SN'],\n",
       " '1574-1656': ['same-unit', 'NN'],\n",
       " '1607-1656': ['same-unit', 'NN'],\n",
       " '1607-1646': ['restatement', 'NN'],\n",
       " '1682-1700': ['organization', 'SN'],\n",
       " '1758-1789': ['joint', 'NN'],\n",
       " '1831-1901': ['adversative', 'SN'],\n",
       " '1851-1901': ['attribution', 'SN'],\n",
       " '1921-2012': ['attribution', 'SN'],\n",
       " '1963-2012': ['joint', 'NN'],\n",
       " '2039-2139': ['explanation', 'NS'],\n",
       " '2039-2128': ['joint', 'NN'],\n",
       " '2068-2128': ['joint', 'NN'],\n",
       " '2079-2128': ['joint', 'NN'],\n",
       " '2094-2128': ['joint', 'NN'],\n",
       " '2221-2301': ['explanation', 'NS'],\n",
       " '2221-2290': ['same-unit', 'NN'],\n",
       " '2265-2290': ['joint', 'NN'],\n",
       " '2350-2469': ['explanation', 'NS'],\n",
       " '2350-2458': ['attribution', 'SN'],\n",
       " '2412-2458': ['joint', 'NN'],\n",
       " '2412-2420': ['elaboration', 'SN'],\n",
       " '2490-2584': ['explanation', 'SN'],\n",
       " '2490-2559': ['same-unit', 'NN'],\n",
       " '2490-2495': ['elaboration', 'NS'],\n",
       " '2514-2559': ['same-unit', 'NN'],\n",
       " '2514-2519': ['elaboration', 'NS'],\n",
       " '2601-2769': ['explanation', 'NS'],\n",
       " '2601-2758': ['same-unit', 'NN'],\n",
       " '2649-2758': ['joint', 'NN'],\n",
       " '2697-2758': ['joint', 'NN'],\n",
       " '2731-2758': ['joint', 'NN'],\n",
       " '2780-2841': ['same-unit', 'NN'],\n",
       " '2795-2841': ['elaboration', 'SN'],\n",
       " '3016-3054': ['explanation', 'NS'],\n",
       " '3016-3043': ['elaboration', 'SN'],\n",
       " '3016-3027': ['mode', 'SN'],\n",
       " '3060-3122': ['explanation', 'NS'],\n",
       " '3060-3111': ['same-unit', 'NN'],\n",
       " '3080-3111': ['elaboration', 'SN'],\n",
       " '3080-3096': ['elaboration', 'SN'],\n",
       " '3141-3224': ['same-unit', 'NN'],\n",
       " '3160-3224': ['joint', 'NN'],\n",
       " '3160-3168': ['elaboration', 'SN'],\n",
       " '3342-3383': ['explanation', 'NS'],\n",
       " '3342-3372': ['joint', 'NN'],\n",
       " '3538-3578': ['adversative', 'SN'],\n",
       " '3642-3699': ['explanation', 'NS'],\n",
       " '3642-3688': ['attribution', 'NS'],\n",
       " '3642-3678': ['joint', 'NN'],\n",
       " '3745-3814': ['explanation', 'NS'],\n",
       " '3745-3803': ['explanation', 'NS'],\n",
       " '3756-3803': ['same-unit', 'NN'],\n",
       " '3756-3759': ['elaboration', 'NS'],\n",
       " '3875-3886': ['explanation', 'NS'],\n",
       " '3914-3970': ['mode', 'SN'],\n",
       " '3955-3970': ['elaboration', 'SN'],\n",
       " '4052-4128': ['attribution', 'NS'],\n",
       " '4052-4117': ['joint', 'NN'],\n",
       " '4095-4117': ['joint', 'NN'],\n",
       " '4225-4308': ['mode', 'SN'],\n",
       " '4225-4241': ['joint', 'NN'],\n",
       " '4257-4308': ['same-unit', 'NN'],\n",
       " '4257-4292': ['restatement', 'NN'],\n",
       " '4318-4391': ['same-unit', 'NN'],\n",
       " '4330-4391': ['joint', 'NN'],\n",
       " '4330-4361': ['elaboration', 'SN'],\n",
       " '4384-4391': ['attribution', 'NS'],\n",
       " '4452-4501': ['adversative', 'SN'],\n",
       " '4458-4501': ['same-unit', 'NN'],\n",
       " '4467-4501': ['elaboration', 'SN']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intra_jp_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4fce80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dic_jp = defaultdict(int)\n",
    "dic_gum = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f38a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in intra_jp_all:\n",
    "    for key in doc.keys():\n",
    "        dic_jp[doc[key][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74b709dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'elaboration': 754,\n",
       "             'adversative': 175,\n",
       "             'context': 113,\n",
       "             'same-unit': 637,\n",
       "             'mode': 114,\n",
       "             'joint': 475,\n",
       "             'explanation': 228,\n",
       "             'attribution': 133,\n",
       "             'restatement': 7,\n",
       "             'organization': 2,\n",
       "             'purpose': 38,\n",
       "             'contingency': 40,\n",
       "             'causal': 81,\n",
       "             'topic': 2,\n",
       "             'evaluation': 3})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b38f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in intra_gum_all:\n",
    "    for key in doc.keys():\n",
    "        dic_gum[doc[key][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74fcea26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'elaboration': 551,\n",
       "             'joint': 225,\n",
       "             'same-unit': 256,\n",
       "             'adversative': 111,\n",
       "             'purpose': 128,\n",
       "             'mode': 56,\n",
       "             'context': 100,\n",
       "             'explanation': 157,\n",
       "             'attribution': 153,\n",
       "             'organization': 32,\n",
       "             'causal': 86,\n",
       "             'restatement': 49,\n",
       "             'contingency': 23,\n",
       "             'evaluation': 10,\n",
       "             'topic': 1})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_gum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa62e202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2802"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(doc) for doc in intra_jp_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f946b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(doc) for doc in intra_gum_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b23d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dic_jp.keys():\n",
    "    dic_jp[key] = dic_jp[key] / 2802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dbebec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'elaboration': 0.2690935046395432,\n",
       "             'adversative': 0.06245538900785153,\n",
       "             'context': 0.04032833690221271,\n",
       "             'same-unit': 0.22733761598857957,\n",
       "             'mode': 0.04068522483940043,\n",
       "             'joint': 0.16952177016416844,\n",
       "             'explanation': 0.08137044967880086,\n",
       "             'attribution': 0.04746609564596717,\n",
       "             'restatement': 0.0024982155603140615,\n",
       "             'organization': 0.0007137758743754461,\n",
       "             'purpose': 0.013561741613133477,\n",
       "             'contingency': 0.014275517487508922,\n",
       "             'causal': 0.028907922912205567,\n",
       "             'topic': 0.0007137758743754461,\n",
       "             'evaluation': 0.0010706638115631692})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96c63a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dic_gum.keys():\n",
    "    dic_gum[key] = dic_gum[key] / 1938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "712fc4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'elaboration': 0.28431372549019607,\n",
       "             'joint': 0.11609907120743033,\n",
       "             'same-unit': 0.13209494324045407,\n",
       "             'adversative': 0.05727554179566564,\n",
       "             'purpose': 0.06604747162022703,\n",
       "             'mode': 0.02889576883384933,\n",
       "             'context': 0.05159958720330237,\n",
       "             'explanation': 0.08101135190918472,\n",
       "             'attribution': 0.07894736842105263,\n",
       "             'organization': 0.016511867905056758,\n",
       "             'causal': 0.04437564499484004,\n",
       "             'restatement': 0.025283797729618165,\n",
       "             'contingency': 0.011867905056759546,\n",
       "             'evaluation': 0.005159958720330237,\n",
       "             'topic': 0.0005159958720330237})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_gum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
